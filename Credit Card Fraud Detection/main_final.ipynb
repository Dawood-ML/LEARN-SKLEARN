{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3bf34dd",
   "metadata": {},
   "source": [
    "### PROJECT - Credit Card Fraud Detection\n",
    "\n",
    "#### **6. Optuna Optimization for the Best Pipeline**\n",
    "\n",
    "Our goal is to create an Optuna study that finds the best combination of:\n",
    "1.  **Imbalance Handling Strategy**: SMOTE vs. Random Undersampling.\n",
    "2.  **Classifier**: A fast linear model (`LogisticRegression`) vs. a powerful tree ensemble (`LightGBM`).\n",
    "3.  **Hyperparameters** for the chosen classifier.\n",
    "\n",
    "We will optimize for the **F1-score**, as it provides a good balance between precision and recall, which is a common starting point for imbalanced problems.\n",
    "\n",
    "**Implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1a8c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold,\n",
    "    cross_val_score\n",
    ")\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed1a3632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler()\n",
    "df['scaled_amount'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "df['scaled_time'] = scaler.fit_transform(df['Time'].values.reshape(-1, 1))\n",
    "\n",
    "# Drop the original columns\n",
    "df.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "\n",
    "scaled_amount = df.pop('scaled_amount')\n",
    "scaled_time = df.pop('scaled_time')\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "#  Use stratify=y, it's absolutely critical here.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f97681",
   "metadata": {},
   "source": [
    "**Define the optuna objective function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a5286a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might be the most complex objective function yet, but it follows the same logic\n",
    "def objective(trial):\n",
    "    # 1. Suggest the imbalance handling strategy\n",
    "    resampling_strategy = trial.suggest_categorical('resampling', ['smote','under', 'none'])\n",
    "    \n",
    "    # 2. Suggest the classifier\n",
    "    classifier_name = trial.suggest_categorical('classifier', ['LogisticRegression', 'LightGBM'])\n",
    "\n",
    "    # 3. Define the pipeline steps based on choices\n",
    "    if resampling_strategy == 'smote':\n",
    "        resampler = SMOTE(random_state=42)\n",
    "    elif resampling_strategy == 'under':\n",
    "        resampler = RandomUnderSampler(random_state=42)\n",
    "    else:\n",
    "        # Passthrough if no resampling is chosen\n",
    "        resampler = 'passthrough'\n",
    "    # Suggest Hyperparameters for the chosen classifier\n",
    "    if classifier_name == 'LogisticRegression':\n",
    "        C = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "        # Add class_weight as an option, especially when 'resampling' is 'none'\n",
    "        use_class_weight = trial.suggest_categorical('lr_class_weight', [True, False])\n",
    "        \n",
    "        class_weight = 'balanced' if use_class_weight else None\n",
    "\n",
    "        classifier = LogisticRegression(C=C, class_weight=class_weight,\n",
    "                                        random_state=42,\n",
    "                                        solver='liblinear')\n",
    "\n",
    "    else: # LIGHT GBM\n",
    "        lgbm_params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 200, 1000),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.03),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 1e2, log=True),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "            'is_unbalance': True, # LightGBM has its own imbalance handling\n",
    "            'n_jobs':-1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        classifier = lgb.LGBMClassifier(**lgbm_params)\n",
    "    \n",
    "    # Create the full pipeline\n",
    "    pipeline = ImbPipeline(steps=[\n",
    "        ('resampler', resampler),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    # Evaluate using Cross validation\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=3, # Use 3 splits for speed\n",
    "                         shuffle=True,\n",
    "                         random_state=42) \n",
    "    score = cross_val_score(pipeline, X_train, y_train, scoring='f1', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    return score.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20d83a4",
   "metadata": {},
   "source": [
    "**Run the Optuna study**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb39c1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 19:27:22,182] A new study created in memory with name: Fraud_detection_optimization\n",
      "[I 2025-11-15 19:27:31,711] Trial 0 finished with value: 0.11341150630779452 and parameters: {'resampling': 'none', 'classifier': 'LogisticRegression', 'C': 51.702938342843346, 'lr_class_weight': True}. Best is trial 0 with value: 0.11341150630779452.\n",
      "[I 2025-11-15 19:27:37,926] Trial 1 finished with value: 0.09376313019820992 and parameters: {'resampling': 'under', 'classifier': 'LightGBM', 'n_estimators': 376, 'learning_rate': 0.018525199266155517, 'num_leaves': 94, 'max_depth': 9, 'min_child_samples': 34, 'subsample': 0.9966345736571192, 'colsample_bytree': 0.5750757766822803, 'reg_alpha': 0.0023104447002549166, 'reg_lambda': 0.08695316058063476}. Best is trial 0 with value: 0.11341150630779452.\n",
      "[I 2025-11-15 19:27:47,603] Trial 2 finished with value: 0.10669999683904147 and parameters: {'resampling': 'smote', 'classifier': 'LogisticRegression', 'C': 0.09413480529543895, 'lr_class_weight': False}. Best is trial 0 with value: 0.11341150630779452.\n",
      "[I 2025-11-15 19:27:49,747] Trial 3 finished with value: 0.711037779832318 and parameters: {'resampling': 'none', 'classifier': 'LogisticRegression', 'C': 0.005561021312451553, 'lr_class_weight': False}. Best is trial 3 with value: 0.711037779832318.\n",
      "[I 2025-11-15 19:27:53,109] Trial 4 finished with value: 0.7375201839521176 and parameters: {'resampling': 'none', 'classifier': 'LogisticRegression', 'C': 0.32048393998507413, 'lr_class_weight': False}. Best is trial 4 with value: 0.7375201839521176.\n",
      "[I 2025-11-15 19:28:13,918] Trial 5 finished with value: 0.786611439329269 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 475, 'learning_rate': 0.015358841934090938, 'num_leaves': 70, 'max_depth': 6, 'min_child_samples': 64, 'subsample': 0.8322581754883835, 'colsample_bytree': 0.9699557654436228, 'reg_alpha': 1.0812127459747132, 'reg_lambda': 0.024504121595976192}. Best is trial 5 with value: 0.786611439329269.\n",
      "[I 2025-11-15 19:28:36,320] Trial 6 finished with value: 0.8195657807935163 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 617, 'learning_rate': 0.021504227951298666, 'num_leaves': 79, 'max_depth': 5, 'min_child_samples': 81, 'subsample': 0.8782176739833157, 'colsample_bytree': 0.8789254412556555, 'reg_alpha': 0.004237200492364797, 'reg_lambda': 0.007405526913328486}. Best is trial 6 with value: 0.8195657807935163.\n",
      "[I 2025-11-15 19:29:52,210] Trial 7 finished with value: 0.8254523766027037 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 903, 'learning_rate': 0.02695603954943386, 'num_leaves': 97, 'max_depth': 9, 'min_child_samples': 40, 'subsample': 0.5790895742082587, 'colsample_bytree': 0.7471130151856944, 'reg_alpha': 0.006147203579219284, 'reg_lambda': 0.003074489219607657}. Best is trial 7 with value: 0.8254523766027037.\n",
      "[I 2025-11-15 19:29:58,622] Trial 8 finished with value: 0.1140566324938737 and parameters: {'resampling': 'none', 'classifier': 'LogisticRegression', 'C': 0.47091649366885163, 'lr_class_weight': True}. Best is trial 7 with value: 0.8254523766027037.\n",
      "[I 2025-11-15 19:29:59,245] Trial 9 finished with value: 0.07399814163706585 and parameters: {'resampling': 'under', 'classifier': 'LogisticRegression', 'C': 0.09128026352424437, 'lr_class_weight': True}. Best is trial 7 with value: 0.8254523766027037.\n",
      "[I 2025-11-15 19:30:53,900] Trial 10 finished with value: 0.5605113922210051 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 974, 'learning_rate': 0.029838828640920214, 'num_leaves': 21, 'max_depth': 10, 'min_child_samples': 12, 'subsample': 0.5523792212039772, 'colsample_bytree': 0.7088958193325657, 'reg_alpha': 60.40126545619247, 'reg_lambda': 9.488274693855374}. Best is trial 7 with value: 0.8254523766027037.\n",
      "[I 2025-11-15 19:31:27,445] Trial 11 finished with value: 0.3751331880151339 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 851, 'learning_rate': 0.02633914539433006, 'num_leaves': 100, 'max_depth': 3, 'min_child_samples': 94, 'subsample': 0.5329402951542443, 'colsample_bytree': 0.8782042847643444, 'reg_alpha': 0.0012599658894114347, 'reg_lambda': 0.0010618050075980243}. Best is trial 7 with value: 0.8254523766027037.\n",
      "[I 2025-11-15 19:32:13,560] Trial 12 finished with value: 0.7238738712497955 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 702, 'learning_rate': 0.02375623000842768, 'num_leaves': 71, 'max_depth': 6, 'min_child_samples': 61, 'subsample': 0.7828768312583181, 'colsample_bytree': 0.7835294073986716, 'reg_alpha': 0.020151327750369426, 'reg_lambda': 0.002012160733596743}. Best is trial 7 with value: 0.8254523766027037.\n",
      "[I 2025-11-15 19:32:26,194] Trial 13 finished with value: 0.24698244932650745 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 202, 'learning_rate': 0.022656085017630855, 'num_leaves': 78, 'max_depth': 4, 'min_child_samples': 93, 'subsample': 0.9135711069662078, 'colsample_bytree': 0.7583274231079895, 'reg_alpha': 0.00010660919568749695, 'reg_lambda': 0.009868904377091417}. Best is trial 7 with value: 0.8254523766027037.\n",
      "[I 2025-11-15 19:32:30,370] Trial 14 finished with value: 0.08578291143319694 and parameters: {'resampling': 'under', 'classifier': 'LightGBM', 'n_estimators': 726, 'learning_rate': 0.011395388513829641, 'num_leaves': 47, 'max_depth': 8, 'min_child_samples': 39, 'subsample': 0.6577337365743416, 'colsample_bytree': 0.8760967102990441, 'reg_alpha': 0.06436492286531713, 'reg_lambda': 0.008152974536911212}. Best is trial 7 with value: 0.8254523766027037.\n",
      "[I 2025-11-15 19:32:50,577] Trial 15 finished with value: 0.840598291443016 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 549, 'learning_rate': 0.02833784535964181, 'num_leaves': 87, 'max_depth': 7, 'min_child_samples': 74, 'subsample': 0.6916270904470508, 'colsample_bytree': 0.6433272122153681, 'reg_alpha': 0.0054757318801105705, 'reg_lambda': 0.38037720127991675}. Best is trial 15 with value: 0.840598291443016.\n",
      "[I 2025-11-15 19:33:25,738] Trial 16 finished with value: 0.7796058068615571 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 539, 'learning_rate': 0.02992790816042422, 'num_leaves': 51, 'max_depth': 8, 'min_child_samples': 45, 'subsample': 0.6784191422890865, 'colsample_bytree': 0.6092027802843241, 'reg_alpha': 0.8152394030812508, 'reg_lambda': 0.9487050108827529}. Best is trial 15 with value: 0.840598291443016.\n",
      "[I 2025-11-15 19:34:27,483] Trial 17 finished with value: 0.8160106962432035 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 864, 'learning_rate': 0.02651514792548528, 'num_leaves': 91, 'max_depth': 8, 'min_child_samples': 75, 'subsample': 0.6515940470600159, 'colsample_bytree': 0.5031398566115648, 'reg_alpha': 0.0006504825493485777, 'reg_lambda': 0.3978757421814841}. Best is trial 15 with value: 0.840598291443016.\n",
      "[I 2025-11-15 19:34:42,566] Trial 18 finished with value: 0.81654448366368 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 397, 'learning_rate': 0.026793273851315694, 'num_leaves': 34, 'max_depth': 10, 'min_child_samples': 24, 'subsample': 0.5788884360788523, 'colsample_bytree': 0.6860585744262399, 'reg_alpha': 0.31809453181801706, 'reg_lambda': 0.5938700852638071}. Best is trial 15 with value: 0.840598291443016.\n",
      "[I 2025-11-15 19:34:47,957] Trial 19 finished with value: 0.08845864350259496 and parameters: {'resampling': 'under', 'classifier': 'LightGBM', 'n_estimators': 986, 'learning_rate': 0.018575907510756128, 'num_leaves': 89, 'max_depth': 7, 'min_child_samples': 52, 'subsample': 0.6992722635944914, 'colsample_bytree': 0.6304864612028324, 'reg_alpha': 0.017478200514880436, 'reg_lambda': 0.09345787581737715}. Best is trial 15 with value: 0.840598291443016.\n",
      "[I 2025-11-15 19:35:18,603] Trial 20 finished with value: 0.8421538461538461 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 679, 'learning_rate': 0.024671346447782853, 'num_leaves': 62, 'max_depth': 7, 'min_child_samples': 75, 'subsample': 0.5952201812519851, 'colsample_bytree': 0.8046942268304549, 'reg_alpha': 0.00013389380796804663, 'reg_lambda': 4.15716640747683}. Best is trial 20 with value: 0.8421538461538461.\n",
      "[I 2025-11-15 19:35:46,486] Trial 21 finished with value: 0.8317156495557025 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 659, 'learning_rate': 0.02515392188280152, 'num_leaves': 62, 'max_depth': 7, 'min_child_samples': 73, 'subsample': 0.606965444169268, 'colsample_bytree': 0.8103692641780119, 'reg_alpha': 0.00011017893753554523, 'reg_lambda': 7.346386089881518}. Best is trial 20 with value: 0.8421538461538461.\n",
      "[I 2025-11-15 19:36:13,502] Trial 22 finished with value: 0.8400400258821444 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 682, 'learning_rate': 0.024283654272414336, 'num_leaves': 61, 'max_depth': 7, 'min_child_samples': 74, 'subsample': 0.6212523949276736, 'colsample_bytree': 0.7782980240778257, 'reg_alpha': 0.00013530290229045398, 'reg_lambda': 8.999254934044664}. Best is trial 20 with value: 0.8421538461538461.\n",
      "[I 2025-11-15 19:36:41,141] Trial 23 finished with value: 0.8349136182117155 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 763, 'learning_rate': 0.020697511189636666, 'num_leaves': 58, 'max_depth': 6, 'min_child_samples': 84, 'subsample': 0.7335317879213096, 'colsample_bytree': 0.8311201128107581, 'reg_alpha': 0.0004707266788695732, 'reg_lambda': 2.3817731353772}. Best is trial 20 with value: 0.8421538461538461.\n",
      "[I 2025-11-15 19:37:01,041] Trial 24 finished with value: 0.8393357293080701 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 561, 'learning_rate': 0.024263250365638547, 'num_leaves': 41, 'max_depth': 7, 'min_child_samples': 68, 'subsample': 0.5008798636292616, 'colsample_bytree': 0.6774871392559273, 'reg_alpha': 0.00019690219951971254, 'reg_lambda': 3.601088223627229}. Best is trial 20 with value: 0.8421538461538461.\n",
      "[I 2025-11-15 19:37:27,115] Trial 25 finished with value: 0.8031181704105687 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 769, 'learning_rate': 0.028472558461133772, 'num_leaves': 67, 'max_depth': 5, 'min_child_samples': 83, 'subsample': 0.6210865911566565, 'colsample_bytree': 0.950488091321906, 'reg_alpha': 0.000588574624986786, 'reg_lambda': 1.9195777306941444}. Best is trial 20 with value: 0.8421538461538461.\n",
      "[I 2025-11-15 19:37:44,341] Trial 26 finished with value: 0.7134265734265733 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 479, 'learning_rate': 0.02304426405873692, 'num_leaves': 82, 'max_depth': 7, 'min_child_samples': 100, 'subsample': 0.7367295876786164, 'colsample_bytree': 0.7258747032951549, 'reg_alpha': 20.189825223039644, 'reg_lambda': 0.2722927594561965}. Best is trial 20 with value: 0.8421538461538461.\n",
      "[I 2025-11-15 19:38:01,996] Trial 27 finished with value: 0.8223149726361999 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 641, 'learning_rate': 0.02810746648038373, 'num_leaves': 29, 'max_depth': 5, 'min_child_samples': 59, 'subsample': 0.6197926967715005, 'colsample_bytree': 0.6572614318267039, 'reg_alpha': 0.00034153041604396967, 'reg_lambda': 4.395543393378665}. Best is trial 20 with value: 0.8421538461538461.\n",
      "[I 2025-11-15 19:38:26,840] Trial 28 finished with value: 0.8494307400379507 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 523, 'learning_rate': 0.025284996238527764, 'num_leaves': 59, 'max_depth': 8, 'min_child_samples': 74, 'subsample': 0.7914577772283269, 'colsample_bytree': 0.8252510963203155, 'reg_alpha': 0.018315222065319416, 'reg_lambda': 1.5763050210000298}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:38:28,564] Trial 29 finished with value: 0.633809611039873 and parameters: {'resampling': 'none', 'classifier': 'LogisticRegression', 'C': 0.00020763086145554385, 'lr_class_weight': False}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:38:48,096] Trial 30 finished with value: 0.8372155934102311 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 364, 'learning_rate': 0.025327519445578796, 'num_leaves': 49, 'max_depth': 9, 'min_child_samples': 51, 'subsample': 0.7986914049132781, 'colsample_bytree': 0.8372704679283312, 'reg_alpha': 0.038461719603531654, 'reg_lambda': 1.2970483423848744}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:39:12,282] Trial 31 finished with value: 0.826212601803153 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 529, 'learning_rate': 0.028251005929814495, 'num_leaves': 56, 'max_depth': 8, 'min_child_samples': 77, 'subsample': 0.7015007240819213, 'colsample_bytree': 0.7910786359809755, 'reg_alpha': 0.006971001614334385, 'reg_lambda': 4.160704015644475}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:39:39,910] Trial 32 finished with value: 0.8442000496958681 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 666, 'learning_rate': 0.022148075149284192, 'num_leaves': 65, 'max_depth': 7, 'min_child_samples': 70, 'subsample': 0.7747034342541309, 'colsample_bytree': 0.9195630350977145, 'reg_alpha': 0.21031694792674716, 'reg_lambda': 0.18930122370360164}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:40:05,758] Trial 33 finished with value: 0.845985932573369 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 584, 'learning_rate': 0.022055409494318463, 'num_leaves': 74, 'max_depth': 8, 'min_child_samples': 68, 'subsample': 0.7764688381394865, 'colsample_bytree': 0.9121128677675103, 'reg_alpha': 0.14892289189421595, 'reg_lambda': 0.23344005968247358}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:40:30,125] Trial 34 finished with value: 0.8369195498706926 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 451, 'learning_rate': 0.019128027692282966, 'num_leaves': 74, 'max_depth': 8, 'min_child_samples': 69, 'subsample': 0.8256604913142783, 'colsample_bytree': 0.9140338479162782, 'reg_alpha': 0.20272273504040375, 'reg_lambda': 0.19359622798462295}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:40:30,765] Trial 35 finished with value: 0.059536213793407504 and parameters: {'resampling': 'under', 'classifier': 'LogisticRegression', 'C': 80.89352510316907, 'lr_class_weight': True}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:40:50,612] Trial 36 finished with value: 0.8324566365007541 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 598, 'learning_rate': 0.02193979306124946, 'num_leaves': 66, 'max_depth': 9, 'min_child_samples': 88, 'subsample': 0.7691368637500331, 'colsample_bytree': 0.9315822268273606, 'reg_alpha': 4.734245559444472, 'reg_lambda': 0.05889775641349253}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:40:52,689] Trial 37 finished with value: 0.10410078328481247 and parameters: {'resampling': 'none', 'classifier': 'LogisticRegression', 'C': 0.00015175305636117907, 'lr_class_weight': True}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:41:17,331] Trial 38 finished with value: 0.7758301046745638 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 787, 'learning_rate': 0.017039389261327594, 'num_leaves': 11, 'max_depth': 8, 'min_child_samples': 67, 'subsample': 0.8732643639206746, 'colsample_bytree': 0.9953725971461475, 'reg_alpha': 0.14797484304771685, 'reg_lambda': 0.17849397390959748}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:41:41,921] Trial 39 finished with value: 0.8440748390190688 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 595, 'learning_rate': 0.02013571032780512, 'num_leaves': 63, 'max_depth': 9, 'min_child_samples': 57, 'subsample': 0.9666620043646643, 'colsample_bytree': 0.8547819151296543, 'reg_alpha': 0.7983268988800218, 'reg_lambda': 0.048374742384915764}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:41:42,374] Trial 40 finished with value: 0.06514661014419203 and parameters: {'resampling': 'under', 'classifier': 'LogisticRegression', 'C': 5.286055993621554, 'lr_class_weight': False}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:42:06,513] Trial 41 finished with value: 0.8450369285234695 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 585, 'learning_rate': 0.019982513971180404, 'num_leaves': 64, 'max_depth': 9, 'min_child_samples': 57, 'subsample': 0.9808080405466765, 'colsample_bytree': 0.8500151564643978, 'reg_alpha': 0.6632965395245581, 'reg_lambda': 0.07025223751380612}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:42:31,385] Trial 42 finished with value: 0.8412370088719898 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 593, 'learning_rate': 0.020106956561251527, 'num_leaves': 54, 'max_depth': 9, 'min_child_samples': 58, 'subsample': 0.9997563040577104, 'colsample_bytree': 0.9049697945783881, 'reg_alpha': 0.7152798394457089, 'reg_lambda': 0.05409835367914904}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:42:53,107] Trial 43 finished with value: 0.8311395811395812 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 499, 'learning_rate': 0.01733747609683314, 'num_leaves': 75, 'max_depth': 9, 'min_child_samples': 54, 'subsample': 0.9546504715005074, 'colsample_bytree': 0.8405431439068869, 'reg_alpha': 2.7059224843207286, 'reg_lambda': 0.027620296606792938}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:43:13,727] Trial 44 finished with value: 0.8367549713973276 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 423, 'learning_rate': 0.02106888672155352, 'num_leaves': 68, 'max_depth': 10, 'min_child_samples': 64, 'subsample': 0.9532766248148352, 'colsample_bytree': 0.8699635278480917, 'reg_alpha': 0.3783753685612946, 'reg_lambda': 0.03225082271975514}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:43:30,240] Trial 45 finished with value: 0.7850760350760351 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 337, 'learning_rate': 0.016892109405167426, 'num_leaves': 82, 'max_depth': 9, 'min_child_samples': 47, 'subsample': 0.9549360566542453, 'colsample_bytree': 0.9706930343457548, 'reg_alpha': 2.2158790321035386, 'reg_lambda': 0.14649504688677142}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:43:59,903] Trial 46 finished with value: 0.8431990431909498 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 622, 'learning_rate': 0.021862445477534527, 'num_leaves': 44, 'max_depth': 8, 'min_child_samples': 63, 'subsample': 0.857316048374649, 'colsample_bytree': 0.8998860934649847, 'reg_alpha': 0.055352330004186136, 'reg_lambda': 0.061396737742134805}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:44:26,659] Trial 47 finished with value: 0.8474207990337023 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 586, 'learning_rate': 0.019448356022729388, 'num_leaves': 71, 'max_depth': 10, 'min_child_samples': 58, 'subsample': 0.9198894964977563, 'colsample_bytree': 0.8526725909111429, 'reg_alpha': 0.11931064338176013, 'reg_lambda': 0.014459718856507004}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:44:55,001] Trial 48 finished with value: 0.8471819020800723 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 505, 'learning_rate': 0.019296750254894645, 'num_leaves': 71, 'max_depth': 10, 'min_child_samples': 68, 'subsample': 0.8201608089107622, 'colsample_bytree': 0.9320545372618054, 'reg_alpha': 0.01965289374410167, 'reg_lambda': 0.014656609330529653}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:44:55,641] Trial 49 finished with value: 0.03842196727495223 and parameters: {'resampling': 'under', 'classifier': 'LogisticRegression', 'C': 0.005418974033673179, 'lr_class_weight': True}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:45:22,925] Trial 50 finished with value: 0.8489564209450169 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 508, 'learning_rate': 0.01460530714757487, 'num_leaves': 72, 'max_depth': 10, 'min_child_samples': 81, 'subsample': 0.9062616925675594, 'colsample_bytree': 0.9448145886151232, 'reg_alpha': 0.017818648896073517, 'reg_lambda': 0.014136574066593025}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:45:50,389] Trial 51 finished with value: 0.8435226084544309 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 497, 'learning_rate': 0.014615253020963916, 'num_leaves': 72, 'max_depth': 10, 'min_child_samples': 79, 'subsample': 0.904908744492251, 'colsample_bytree': 0.9419298519535216, 'reg_alpha': 0.017052193932244105, 'reg_lambda': 0.013126126812939301}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:46:12,316] Trial 52 finished with value: 0.7726223877752756 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 438, 'learning_rate': 0.01216091162137042, 'num_leaves': 79, 'max_depth': 10, 'min_child_samples': 64, 'subsample': 0.9180407569117036, 'colsample_bytree': 0.9667871333880365, 'reg_alpha': 0.10230030241097886, 'reg_lambda': 0.018445427928347916}. Best is trial 28 with value: 0.8494307400379507.\n",
      "[I 2025-11-15 19:46:39,323] Trial 53 finished with value: 0.8543193529380256 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 522, 'learning_rate': 0.015641641799683657, 'num_leaves': 71, 'max_depth': 10, 'min_child_samples': 87, 'subsample': 0.8237748914094599, 'colsample_bytree': 0.9026589638584012, 'reg_alpha': 0.030191790306561037, 'reg_lambda': 0.004000142019614431}. Best is trial 53 with value: 0.8543193529380256.\n",
      "[I 2025-11-15 19:47:26,717] Trial 54 finished with value: 0.6938592346876659 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 492, 'learning_rate': 0.01414305235759762, 'num_leaves': 71, 'max_depth': 10, 'min_child_samples': 88, 'subsample': 0.8167180638543368, 'colsample_bytree': 0.8867785720579789, 'reg_alpha': 0.010858133376030137, 'reg_lambda': 0.002405744873840528}. Best is trial 53 with value: 0.8543193529380256.\n",
      "[I 2025-11-15 19:47:58,904] Trial 55 finished with value: 0.8513225904530253 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 544, 'learning_rate': 0.01595873665552971, 'num_leaves': 84, 'max_depth': 10, 'min_child_samples': 88, 'subsample': 0.8550167394959431, 'colsample_bytree': 0.9903548698822686, 'reg_alpha': 0.03307370321388279, 'reg_lambda': 0.00429423546299583}. Best is trial 53 with value: 0.8543193529380256.\n",
      "[I 2025-11-15 19:48:30,834] Trial 56 finished with value: 0.844520256244898 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 525, 'learning_rate': 0.015990507189524814, 'num_leaves': 87, 'max_depth': 10, 'min_child_samples': 93, 'subsample': 0.8469095492947641, 'colsample_bytree': 0.9668585020129428, 'reg_alpha': 0.0029818243686468653, 'reg_lambda': 0.0047712793606751736}. Best is trial 53 with value: 0.8543193529380256.\n",
      "[I 2025-11-15 19:48:59,113] Trial 57 finished with value: 0.8157514720289084 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 464, 'learning_rate': 0.013560791103081705, 'num_leaves': 82, 'max_depth': 10, 'min_child_samples': 86, 'subsample': 0.8915803634108879, 'colsample_bytree': 0.9827539786386557, 'reg_alpha': 0.03318085584118613, 'reg_lambda': 0.005101523038922617}. Best is trial 53 with value: 0.8543193529380256.\n",
      "[I 2025-11-15 19:49:31,245] Trial 58 finished with value: 0.6021408983720983 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 299, 'learning_rate': 0.012995011627282099, 'num_leaves': 96, 'max_depth': 10, 'min_child_samples': 97, 'subsample': 0.9226724121107799, 'colsample_bytree': 0.9453555950201247, 'reg_alpha': 0.0014801251581029187, 'reg_lambda': 0.004919932110661941}. Best is trial 53 with value: 0.8543193529380256.\n",
      "[I 2025-11-15 19:50:03,217] Trial 59 finished with value: 0.800922359906589 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 556, 'learning_rate': 0.010072734759123672, 'num_leaves': 78, 'max_depth': 10, 'min_child_samples': 90, 'subsample': 0.8607954576899243, 'colsample_bytree': 0.9979088438497605, 'reg_alpha': 0.009335186306793674, 'reg_lambda': 0.0011215025419253175}. Best is trial 53 with value: 0.8543193529380256.\n",
      "[I 2025-11-15 19:50:27,998] Trial 60 finished with value: 0.8248555432472081 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 410, 'learning_rate': 0.015466042572527693, 'num_leaves': 85, 'max_depth': 9, 'min_child_samples': 81, 'subsample': 0.7978217131944997, 'colsample_bytree': 0.8908146563225486, 'reg_alpha': 0.02910834217647605, 'reg_lambda': 0.012249502665630291}. Best is trial 53 with value: 0.8543193529380256.\n",
      "[I 2025-11-15 19:50:57,460] Trial 61 finished with value: 0.8478761976885845 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 525, 'learning_rate': 0.017833114454639747, 'num_leaves': 76, 'max_depth': 10, 'min_child_samples': 81, 'subsample': 0.8388933898903442, 'colsample_bytree': 0.9257944896243768, 'reg_alpha': 0.08133327931569284, 'reg_lambda': 0.0033580074239502053}. Best is trial 53 with value: 0.8543193529380256.\n",
      "[I 2025-11-15 19:51:26,296] Trial 62 finished with value: 0.8554199320126307 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 527, 'learning_rate': 0.018793941772754376, 'num_leaves': 77, 'max_depth': 10, 'min_child_samples': 80, 'subsample': 0.8372879281607294, 'colsample_bytree': 0.9316641885353012, 'reg_alpha': 0.07178625495119254, 'reg_lambda': 0.001672122105071431}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:51:54,648] Trial 63 finished with value: 0.8491406923239517 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 553, 'learning_rate': 0.017752058661158955, 'num_leaves': 93, 'max_depth': 10, 'min_child_samples': 81, 'subsample': 0.8467114377422051, 'colsample_bytree': 0.8678423855341286, 'reg_alpha': 0.07533329796112159, 'reg_lambda': 0.0015139521903614916}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:52:24,204] Trial 64 finished with value: 0.8468246828354783 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 534, 'learning_rate': 0.01837637774397578, 'num_leaves': 89, 'max_depth': 10, 'min_child_samples': 80, 'subsample': 0.8403330031116863, 'colsample_bytree': 0.8689140543288151, 'reg_alpha': 0.06744688928522583, 'reg_lambda': 0.0014812476036329234}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:52:49,613] Trial 65 finished with value: 0.8475276624033827 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 459, 'learning_rate': 0.01793000635620368, 'num_leaves': 93, 'max_depth': 9, 'min_child_samples': 91, 'subsample': 0.8906804972314653, 'colsample_bytree': 0.9542225908736923, 'reg_alpha': 0.06819759949071746, 'reg_lambda': 0.0035890523862152925}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:52:52,259] Trial 66 finished with value: 0.08457328747940347 and parameters: {'resampling': 'under', 'classifier': 'LightGBM', 'n_estimators': 558, 'learning_rate': 0.016191762343085246, 'num_leaves': 99, 'max_depth': 3, 'min_child_samples': 83, 'subsample': 0.8026172044559979, 'colsample_bytree': 0.9221005902509319, 'reg_alpha': 0.00408019007253113, 'reg_lambda': 0.001961097167471685}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:53:19,786] Trial 67 finished with value: 0.8301363862004595 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 520, 'learning_rate': 0.014517043822389185, 'num_leaves': 85, 'max_depth': 10, 'min_child_samples': 85, 'subsample': 0.8696607467783827, 'colsample_bytree': 0.7572509645629775, 'reg_alpha': 0.012585549901127813, 'reg_lambda': 0.007765335056119357}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:53:22,183] Trial 68 finished with value: 0.7177892964294003 and parameters: {'resampling': 'none', 'classifier': 'LogisticRegression', 'C': 0.008314555902496235, 'lr_class_weight': False}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:54:24,326] Trial 69 finished with value: 0.7831563621143932 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 629, 'learning_rate': 0.017700703030224748, 'num_leaves': 77, 'max_depth': 10, 'min_child_samples': 78, 'subsample': 0.8427835009436073, 'colsample_bytree': 0.9802521097170886, 'reg_alpha': 0.04519933013568772, 'reg_lambda': 0.002950451773184245}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:54:45,947] Trial 70 finished with value: 0.8199781034945858 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 383, 'learning_rate': 0.016375375934765287, 'num_leaves': 93, 'max_depth': 9, 'min_child_samples': 97, 'subsample': 0.7568790391463879, 'colsample_bytree': 0.8230628655954764, 'reg_alpha': 0.027249471917315256, 'reg_lambda': 0.0015298640094751803}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:55:12,062] Trial 71 finished with value: 0.8509299805266277 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 466, 'learning_rate': 0.018149075085886483, 'num_leaves': 93, 'max_depth': 9, 'min_child_samples': 90, 'subsample': 0.8800180291042256, 'colsample_bytree': 0.9569934728846065, 'reg_alpha': 0.0693955444445684, 'reg_lambda': 0.0036350539411068574}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:55:44,160] Trial 72 finished with value: 0.8494290355230508 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 554, 'learning_rate': 0.015195527261676518, 'num_leaves': 90, 'max_depth': 10, 'min_child_samples': 87, 'subsample': 0.8901543863091309, 'colsample_bytree': 0.9542386509033043, 'reg_alpha': 0.08051186576338076, 'reg_lambda': 0.003306424721753053}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:56:12,532] Trial 73 finished with value: 0.8298654064709492 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 477, 'learning_rate': 0.015197340550591555, 'num_leaves': 96, 'max_depth': 9, 'min_child_samples': 95, 'subsample': 0.8904015226362368, 'colsample_bytree': 0.9535508706297575, 'reg_alpha': 0.3377086318154839, 'reg_lambda': 0.0010103396122528733}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:56:42,982] Trial 74 finished with value: 0.8540674504402851 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 563, 'learning_rate': 0.015509370754753832, 'num_leaves': 91, 'max_depth': 10, 'min_child_samples': 88, 'subsample': 0.8110237948486814, 'colsample_bytree': 0.8972872169767885, 'reg_alpha': 0.04325659463501359, 'reg_lambda': 0.0020027639904970423}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:57:17,173] Trial 75 finished with value: 0.8551931270699392 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 552, 'learning_rate': 0.015454767695813144, 'num_leaves': 91, 'max_depth': 10, 'min_child_samples': 89, 'subsample': 0.8079300443388187, 'colsample_bytree': 0.9034908896407128, 'reg_alpha': 0.047321042776900114, 'reg_lambda': 0.0018559545530537442}. Best is trial 62 with value: 0.8554199320126307.\n",
      "[I 2025-11-15 19:58:11,743] Trial 76 finished with value: 0.8654964639927046 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 944, 'learning_rate': 0.015450055607771851, 'num_leaves': 90, 'max_depth': 9, 'min_child_samples': 90, 'subsample': 0.8068983512216086, 'colsample_bytree': 0.8866408824579773, 'reg_alpha': 0.03614657920171625, 'reg_lambda': 0.0063086938162501376}. Best is trial 76 with value: 0.8654964639927046.\n",
      "[I 2025-11-15 19:58:54,894] Trial 77 finished with value: 0.8639240317411154 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 931, 'learning_rate': 0.01647869004052746, 'num_leaves': 86, 'max_depth': 9, 'min_child_samples': 100, 'subsample': 0.7924586725828588, 'colsample_bytree': 0.8918716309205298, 'reg_alpha': 0.042040128138970935, 'reg_lambda': 0.0061843868975921075}. Best is trial 76 with value: 0.8654964639927046.\n",
      "[I 2025-11-15 19:59:42,985] Trial 78 finished with value: 0.8662498231876222 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 957, 'learning_rate': 0.016683261504370533, 'num_leaves': 100, 'max_depth': 9, 'min_child_samples': 100, 'subsample': 0.8117090707525394, 'colsample_bytree': 0.8928779363226997, 'reg_alpha': 0.05133994064033974, 'reg_lambda': 0.007026315600915953}. Best is trial 78 with value: 0.8662498231876222.\n",
      "[I 2025-11-15 20:00:29,772] Trial 79 finished with value: 0.8620208138117764 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 933, 'learning_rate': 0.016634342497746712, 'num_leaves': 99, 'max_depth': 9, 'min_child_samples': 100, 'subsample': 0.8118588759554388, 'colsample_bytree': 0.891584614853239, 'reg_alpha': 0.039168780318368894, 'reg_lambda': 0.005893893966960546}. Best is trial 78 with value: 0.8662498231876222.\n",
      "[I 2025-11-15 20:00:30,420] Trial 80 finished with value: 0.06543051653224148 and parameters: {'resampling': 'under', 'classifier': 'LogisticRegression', 'C': 4.921172667999061, 'lr_class_weight': False}. Best is trial 78 with value: 0.8662498231876222.\n",
      "[I 2025-11-15 20:01:22,165] Trial 81 finished with value: 0.8689843145063162 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 943, 'learning_rate': 0.015783903045243294, 'num_leaves': 98, 'max_depth': 9, 'min_child_samples': 100, 'subsample': 0.8113512643997581, 'colsample_bytree': 0.8872658751201604, 'reg_alpha': 0.03480088217582327, 'reg_lambda': 0.007002621982592425}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:02:09,700] Trial 82 finished with value: 0.8592760561014529 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 943, 'learning_rate': 0.016434959643873207, 'num_leaves': 99, 'max_depth': 9, 'min_child_samples': 100, 'subsample': 0.8109023793566208, 'colsample_bytree': 0.8869200813698894, 'reg_alpha': 0.04392614140797211, 'reg_lambda': 0.006528665318579391}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:02:48,367] Trial 83 finished with value: 0.8458944514997485 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 947, 'learning_rate': 0.016379130580625255, 'num_leaves': 100, 'max_depth': 9, 'min_child_samples': 100, 'subsample': 0.7540607461174884, 'colsample_bytree': 0.879943404592893, 'reg_alpha': 0.19519705951873906, 'reg_lambda': 0.006530128921261651}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:03:40,144] Trial 84 finished with value: 0.8608946887169195 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 905, 'learning_rate': 0.016837460138528205, 'num_leaves': 97, 'max_depth': 9, 'min_child_samples': 97, 'subsample': 0.7888377743008127, 'colsample_bytree': 0.909661050833461, 'reg_alpha': 0.02514906818327082, 'reg_lambda': 0.009036553974383103}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:04:28,171] Trial 85 finished with value: 0.8573507180650038 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 907, 'learning_rate': 0.016908727520874738, 'num_leaves': 97, 'max_depth': 8, 'min_child_samples': 97, 'subsample': 0.7871795175388809, 'colsample_bytree': 0.9092830696462263, 'reg_alpha': 0.006759588719036881, 'reg_lambda': 0.010207801169251199}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:05:11,143] Trial 86 finished with value: 0.8585849097523816 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 900, 'learning_rate': 0.016950680136018234, 'num_leaves': 97, 'max_depth': 8, 'min_child_samples': 97, 'subsample': 0.7221995289500298, 'colsample_bytree': 0.8861664335271915, 'reg_alpha': 0.005436869416452113, 'reg_lambda': 0.009425246870674248}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:05:58,644] Trial 87 finished with value: 0.853312658626835 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 906, 'learning_rate': 0.01670929706032194, 'num_leaves': 98, 'max_depth': 8, 'min_child_samples': 96, 'subsample': 0.7843067227510417, 'colsample_bytree': 0.8620148278869696, 'reg_alpha': 0.005706667223351107, 'reg_lambda': 0.006806309649409093}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:06:48,793] Trial 88 finished with value: 0.8563488144228885 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 954, 'learning_rate': 0.01717594264900986, 'num_leaves': 96, 'max_depth': 8, 'min_child_samples': 100, 'subsample': 0.7243258978691451, 'colsample_bytree': 0.8792792806020507, 'reg_alpha': 0.007445996726472111, 'reg_lambda': 0.00958065816723369}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:07:34,237] Trial 89 finished with value: 0.8512437560571297 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 865, 'learning_rate': 0.01686916363736198, 'num_leaves': 100, 'max_depth': 8, 'min_child_samples': 97, 'subsample': 0.7657535263888674, 'colsample_bytree': 0.8454660424539239, 'reg_alpha': 0.012926071086789594, 'reg_lambda': 0.008904065683437276}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:08:59,996] Trial 90 finished with value: 0.7955766455766456 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 911, 'learning_rate': 0.013737472877680172, 'num_leaves': 97, 'max_depth': 9, 'min_child_samples': 93, 'subsample': 0.7362083444371321, 'colsample_bytree': 0.810956352844793, 'reg_alpha': 0.0016519363946348364, 'reg_lambda': 0.01055469532839888}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:09:44,768] Trial 91 finished with value: 0.8541025223207367 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 951, 'learning_rate': 0.017331885296060247, 'num_leaves': 95, 'max_depth': 8, 'min_child_samples': 100, 'subsample': 0.7034113213810101, 'colsample_bytree': 0.8826507982030573, 'reg_alpha': 0.007582839454166833, 'reg_lambda': 0.020856828981688533}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:10:25,908] Trial 92 finished with value: 0.8585537216424401 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 996, 'learning_rate': 0.017308778968230677, 'num_leaves': 97, 'max_depth': 8, 'min_child_samples': 98, 'subsample': 0.718712294037128, 'colsample_bytree': 0.5280081815622977, 'reg_alpha': 0.003885852029588529, 'reg_lambda': 0.005970835784538835}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:11:07,560] Trial 93 finished with value: 0.8570992420236206 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 990, 'learning_rate': 0.016474869149066554, 'num_leaves': 98, 'max_depth': 9, 'min_child_samples': 98, 'subsample': 0.7177427092417579, 'colsample_bytree': 0.5363587046123038, 'reg_alpha': 0.0035474164512848054, 'reg_lambda': 0.006660119917937767}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:11:41,208] Trial 94 finished with value: 0.8512585812356979 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 887, 'learning_rate': 0.01877016142460396, 'num_leaves': 100, 'max_depth': 8, 'min_child_samples': 93, 'subsample': 0.6753383538824216, 'colsample_bytree': 0.5678579373239836, 'reg_alpha': 0.021310165943459664, 'reg_lambda': 0.00581569894056093}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:12:26,437] Trial 95 finished with value: 0.8554513889442119 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 824, 'learning_rate': 0.014786679937810994, 'num_leaves': 88, 'max_depth': 9, 'min_child_samples': 95, 'subsample': 0.7837595853936766, 'colsample_bytree': 0.9098482255309025, 'reg_alpha': 0.004759956069932747, 'reg_lambda': 0.01756997899738798}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:13:14,857] Trial 96 finished with value: 0.8615919323817982 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 930, 'learning_rate': 0.017316264249295162, 'num_leaves': 94, 'max_depth': 9, 'min_child_samples': 98, 'subsample': 0.7460959941373609, 'colsample_bytree': 0.8930546033468932, 'reg_alpha': 0.0022858385161927826, 'reg_lambda': 0.008288886927308935}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:14:04,603] Trial 97 finished with value: 0.8592963953347171 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 933, 'learning_rate': 0.016036439216223698, 'num_leaves': 94, 'max_depth': 9, 'min_child_samples': 26, 'subsample': 0.7434547530603125, 'colsample_bytree': 0.7309901621415323, 'reg_alpha': 0.0007714205685148005, 'reg_lambda': 0.0025796259489144634}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:14:07,517] Trial 98 finished with value: 0.11648643834745422 and parameters: {'resampling': 'none', 'classifier': 'LogisticRegression', 'C': 0.0008226423160561748, 'lr_class_weight': True}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:14:14,179] Trial 99 finished with value: 0.08538582714483405 and parameters: {'resampling': 'under', 'classifier': 'LightGBM', 'n_estimators': 928, 'learning_rate': 0.01591067741922959, 'num_leaves': 94, 'max_depth': 9, 'min_child_samples': 24, 'subsample': 0.7439920896195652, 'colsample_bytree': 0.7288077096534659, 'reg_alpha': 0.0007940444550444395, 'reg_lambda': 0.0028109207768804586}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:15:08,137] Trial 100 finished with value: 0.8570525813927574 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 967, 'learning_rate': 0.01508506959639049, 'num_leaves': 94, 'max_depth': 9, 'min_child_samples': 27, 'subsample': 0.7714416288171998, 'colsample_bytree': 0.7785876837624058, 'reg_alpha': 0.0023079686010665968, 'reg_lambda': 0.031120556729189723}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:15:48,372] Trial 101 finished with value: 0.8562560415686802 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 926, 'learning_rate': 0.01756481749332208, 'num_leaves': 91, 'max_depth': 9, 'min_child_samples': 38, 'subsample': 0.7136342279767198, 'colsample_bytree': 0.6094321178607762, 'reg_alpha': 0.00025746988146430955, 'reg_lambda': 0.00826994760497748}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:16:37,982] Trial 102 finished with value: 0.8642952507123391 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 881, 'learning_rate': 0.016015836754341026, 'num_leaves': 98, 'max_depth': 9, 'min_child_samples': 92, 'subsample': 0.6858700954789959, 'colsample_bytree': 0.8892722303243991, 'reg_alpha': 0.0009240440294101774, 'reg_lambda': 0.005562084919649979}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:17:25,654] Trial 103 finished with value: 0.8542688744607977 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 883, 'learning_rate': 0.01588943195235144, 'num_leaves': 100, 'max_depth': 9, 'min_child_samples': 17, 'subsample': 0.6642843571456322, 'colsample_bytree': 0.7012889514750565, 'reg_alpha': 0.0010266785082860622, 'reg_lambda': 0.0053342333201391225}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:18:15,619] Trial 104 finished with value: 0.8580648867933163 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 840, 'learning_rate': 0.013873946073601592, 'num_leaves': 95, 'max_depth': 9, 'min_child_samples': 92, 'subsample': 0.647749016304323, 'colsample_bytree': 0.8919679546131791, 'reg_alpha': 0.0025916747140265744, 'reg_lambda': 0.007657584252514705}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:19:07,218] Trial 105 finished with value: 0.8559396289097677 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 972, 'learning_rate': 0.013093728803759586, 'num_leaves': 88, 'max_depth': 9, 'min_child_samples': 94, 'subsample': 0.6877686029500932, 'colsample_bytree': 0.86505076175804, 'reg_alpha': 0.00045354198929376574, 'reg_lambda': 0.011877219942963143}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:19:52,017] Trial 106 finished with value: 0.8562437912392425 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 932, 'learning_rate': 0.016701415730987008, 'num_leaves': 98, 'max_depth': 9, 'min_child_samples': 100, 'subsample': 0.7619270338307105, 'colsample_bytree': 0.7346528308882627, 'reg_alpha': 0.0019114324144263518, 'reg_lambda': 0.0024766408584559626}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:20:39,560] Trial 107 finished with value: 0.8612335905050569 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 888, 'learning_rate': 0.014355838129528833, 'num_leaves': 92, 'max_depth': 9, 'min_child_samples': 95, 'subsample': 0.8292187519870635, 'colsample_bytree': 0.9215032551803841, 'reg_alpha': 0.0010087196593413542, 'reg_lambda': 0.004824283395910696}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:21:22,960] Trial 108 finished with value: 0.8533947865142567 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 811, 'learning_rate': 0.014271490618604688, 'num_leaves': 92, 'max_depth': 9, 'min_child_samples': 95, 'subsample': 0.8279531295052867, 'colsample_bytree': 0.9195289995942834, 'reg_alpha': 0.0007532664725640066, 'reg_lambda': 0.004474228533358774}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:22:13,478] Trial 109 finished with value: 0.861217400100204 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 862, 'learning_rate': 0.01483422308087278, 'num_leaves': 87, 'max_depth': 9, 'min_child_samples': 91, 'subsample': 0.7983669404358722, 'colsample_bytree': 0.9363963728712519, 'reg_alpha': 0.00104165237935173, 'reg_lambda': 0.004221342708764201}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:23:16,682] Trial 110 finished with value: 0.6570576656745465 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 867, 'learning_rate': 0.014843917755239657, 'num_leaves': 86, 'max_depth': 6, 'min_child_samples': 93, 'subsample': 0.7948796386856425, 'colsample_bytree': 0.9342928037903441, 'reg_alpha': 0.0010498723611262906, 'reg_lambda': 0.002412502950270833}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:24:07,567] Trial 111 finished with value: 0.8635063752276867 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 934, 'learning_rate': 0.015783955854259322, 'num_leaves': 81, 'max_depth': 9, 'min_child_samples': 91, 'subsample': 0.81733591027707, 'colsample_bytree': 0.897592381484093, 'reg_alpha': 0.0004387309957131675, 'reg_lambda': 0.004133833844873149}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:24:55,336] Trial 112 finished with value: 0.8530042578120914 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 888, 'learning_rate': 0.013298577024895952, 'num_leaves': 81, 'max_depth': 9, 'min_child_samples': 91, 'subsample': 0.8204065074193475, 'colsample_bytree': 0.8579214801071411, 'reg_alpha': 0.0005403250885675013, 'reg_lambda': 0.004307656647997956}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:25:47,327] Trial 113 finished with value: 0.8648610061308474 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 970, 'learning_rate': 0.015749270515545866, 'num_leaves': 84, 'max_depth': 9, 'min_child_samples': 98, 'subsample': 0.799292060009006, 'colsample_bytree': 0.9155241471748367, 'reg_alpha': 0.00026870640632066235, 'reg_lambda': 0.005193686147499906}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:26:42,140] Trial 114 finished with value: 0.8635687489883163 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 963, 'learning_rate': 0.014905189760311873, 'num_leaves': 84, 'max_depth': 9, 'min_child_samples': 98, 'subsample': 0.8001922928894404, 'colsample_bytree': 0.915400644446013, 'reg_alpha': 0.00014983717114289448, 'reg_lambda': 0.005312371924576325}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:27:36,731] Trial 115 finished with value: 0.8620910052701082 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 976, 'learning_rate': 0.014922518483657384, 'num_leaves': 83, 'max_depth': 9, 'min_child_samples': 95, 'subsample': 0.8297121403530379, 'colsample_bytree': 0.9201743104539993, 'reg_alpha': 0.00010304275063256444, 'reg_lambda': 0.0054049344877119525}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:28:34,766] Trial 116 finished with value: 0.8647642062507193 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 977, 'learning_rate': 0.014439765097627991, 'num_leaves': 80, 'max_depth': 9, 'min_child_samples': 98, 'subsample': 0.8306572944119119, 'colsample_bytree': 0.9225725766829286, 'reg_alpha': 0.0001648148261188295, 'reg_lambda': 0.005498771414794769}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:29:29,582] Trial 117 finished with value: 0.8529396704918527 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 977, 'learning_rate': 0.015370874338884026, 'num_leaves': 84, 'max_depth': 9, 'min_child_samples': 98, 'subsample': 0.7771506639890453, 'colsample_bytree': 0.8718010599591586, 'reg_alpha': 0.00019026969205891982, 'reg_lambda': 0.0054857689765916645}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:29:33,817] Trial 118 finished with value: 0.7395748455586184 and parameters: {'resampling': 'none', 'classifier': 'LogisticRegression', 'C': 6.285406835048445, 'lr_class_weight': False}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:30:30,087] Trial 119 finished with value: 0.8566436828797223 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 1000, 'learning_rate': 0.012055599988365522, 'num_leaves': 81, 'max_depth': 9, 'min_child_samples': 99, 'subsample': 0.8129195428866931, 'colsample_bytree': 0.8960872600433525, 'reg_alpha': 0.00013050939172606582, 'reg_lambda': 0.0038332588648439508}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:30:57,106] Trial 120 finished with value: 0.7054688704305073 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 965, 'learning_rate': 0.012554528306675954, 'num_leaves': 83, 'max_depth': 4, 'min_child_samples': 95, 'subsample': 0.8330377969285002, 'colsample_bytree': 0.9148890280872347, 'reg_alpha': 0.0003269480383415711, 'reg_lambda': 0.007383040943616824}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:31:47,511] Trial 121 finished with value: 0.8640548696844993 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 959, 'learning_rate': 0.01573368039377675, 'num_leaves': 89, 'max_depth': 9, 'min_child_samples': 94, 'subsample': 0.8251102501813437, 'colsample_bytree': 0.9256884823472075, 'reg_alpha': 0.0001880202298238166, 'reg_lambda': 0.005284788856764645}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:32:42,885] Trial 122 finished with value: 0.8635202898071664 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 958, 'learning_rate': 0.015680168216480498, 'num_leaves': 80, 'max_depth': 9, 'min_child_samples': 92, 'subsample': 0.8041862609234544, 'colsample_bytree': 0.8965818959743875, 'reg_alpha': 0.00015948635453774736, 'reg_lambda': 0.003228476354472113}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:33:35,122] Trial 123 finished with value: 0.8670910668794267 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 981, 'learning_rate': 0.014060921661848663, 'num_leaves': 80, 'max_depth': 9, 'min_child_samples': 92, 'subsample': 0.853204923515872, 'colsample_bytree': 0.9271456161532087, 'reg_alpha': 0.00018019736215674952, 'reg_lambda': 0.0029063773264128762}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:34:27,327] Trial 124 finished with value: 0.8671146656047433 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 983, 'learning_rate': 0.014043206003621703, 'num_leaves': 79, 'max_depth': 9, 'min_child_samples': 92, 'subsample': 0.8515809669304816, 'colsample_bytree': 0.9274092583660599, 'reg_alpha': 0.00017321155686450283, 'reg_lambda': 0.003044231008820378}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:35:23,815] Trial 125 finished with value: 0.8643196695242276 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 957, 'learning_rate': 0.013899605798458387, 'num_leaves': 80, 'max_depth': 9, 'min_child_samples': 90, 'subsample': 0.8514258599214392, 'colsample_bytree': 0.9025450628559731, 'reg_alpha': 0.000239488068175608, 'reg_lambda': 0.0028757878333309406}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:35:28,029] Trial 126 finished with value: 0.08494326726132524 and parameters: {'resampling': 'under', 'classifier': 'LightGBM', 'n_estimators': 958, 'learning_rate': 0.01400364037853995, 'num_leaves': 79, 'max_depth': 9, 'min_child_samples': 92, 'subsample': 0.8554365529364778, 'colsample_bytree': 0.9392681780030633, 'reg_alpha': 0.00017970295674291767, 'reg_lambda': 0.003073702984738427}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:36:22,815] Trial 127 finished with value: 0.8647804338265583 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 985, 'learning_rate': 0.014246010016908462, 'num_leaves': 75, 'max_depth': 9, 'min_child_samples': 85, 'subsample': 0.864684885075608, 'colsample_bytree': 0.9272193970686858, 'reg_alpha': 0.0002482856618777631, 'reg_lambda': 0.003245326888957632}. Best is trial 81 with value: 0.8689843145063162.\n",
      "[I 2025-11-15 20:37:20,522] Trial 128 finished with value: 0.8690008435560367 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 984, 'learning_rate': 0.012780243533848863, 'num_leaves': 74, 'max_depth': 9, 'min_child_samples': 85, 'subsample': 0.8527226586764328, 'colsample_bytree': 0.9271778431623495, 'reg_alpha': 0.0002628475526878102, 'reg_lambda': 0.0022441584720108835}. Best is trial 128 with value: 0.8690008435560367.\n",
      "[I 2025-11-15 20:38:07,622] Trial 129 finished with value: 0.8519994789468474 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 986, 'learning_rate': 0.011725902931782424, 'num_leaves': 74, 'max_depth': 9, 'min_child_samples': 83, 'subsample': 0.8673218331236546, 'colsample_bytree': 0.9277413078759225, 'reg_alpha': 0.000274086394851862, 'reg_lambda': 0.6523148474411946}. Best is trial 128 with value: 0.8690008435560367.\n",
      "[I 2025-11-15 20:39:02,076] Trial 130 finished with value: 0.8702454099919538 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 984, 'learning_rate': 0.012884579931656037, 'num_leaves': 68, 'max_depth': 9, 'min_child_samples': 86, 'subsample': 0.8515735476743733, 'colsample_bytree': 0.9614950229666329, 'reg_alpha': 0.00021881931021067107, 'reg_lambda': 0.002003625697370366}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:40:02,743] Trial 131 finished with value: 0.8663370630583745 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 984, 'learning_rate': 0.012619917536713331, 'num_leaves': 68, 'max_depth': 9, 'min_child_samples': 85, 'subsample': 0.8501846135665311, 'colsample_bytree': 0.9644693025807521, 'reg_alpha': 0.0002516542118120834, 'reg_lambda': 0.001287964333229887}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:40:57,034] Trial 132 finished with value: 0.8681860328476869 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 978, 'learning_rate': 0.01261533338021921, 'num_leaves': 68, 'max_depth': 9, 'min_child_samples': 85, 'subsample': 0.8507991877509536, 'colsample_bytree': 0.9601137461848089, 'reg_alpha': 0.00027593542485137586, 'reg_lambda': 0.0011980449583487787}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:41:53,044] Trial 133 finished with value: 0.8616924110702503 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 986, 'learning_rate': 0.011219856637264464, 'num_leaves': 68, 'max_depth': 9, 'min_child_samples': 85, 'subsample': 0.8508201042870038, 'colsample_bytree': 0.9750780070647842, 'reg_alpha': 0.0002472983174395912, 'reg_lambda': 0.0022270947791944965}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:42:51,680] Trial 134 finished with value: 0.8655489964580872 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 1000, 'learning_rate': 0.012773193189172038, 'num_leaves': 75, 'max_depth': 9, 'min_child_samples': 86, 'subsample': 0.8767909975572561, 'colsample_bytree': 0.9573419942747105, 'reg_alpha': 0.00035634090185542093, 'reg_lambda': 0.0012521958831088484}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:43:47,103] Trial 135 finished with value: 0.8642979685995207 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 1000, 'learning_rate': 0.012593869140836643, 'num_leaves': 73, 'max_depth': 9, 'min_child_samples': 86, 'subsample': 0.8801155237273127, 'colsample_bytree': 0.9640194939695663, 'reg_alpha': 0.0003521868652490461, 'reg_lambda': 0.0012766497483992177}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:44:44,834] Trial 136 finished with value: 0.8659336032923952 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 979, 'learning_rate': 0.012717873993162442, 'num_leaves': 76, 'max_depth': 9, 'min_child_samples': 85, 'subsample': 0.8639386804452915, 'colsample_bytree': 0.9467439991878831, 'reg_alpha': 0.0003769182041587789, 'reg_lambda': 0.0012294174352603488}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:46:13,952] Trial 137 finished with value: 0.7638868670293757 and parameters: {'resampling': 'smote', 'classifier': 'LightGBM', 'n_estimators': 976, 'learning_rate': 0.012683352619794948, 'num_leaves': 70, 'max_depth': 8, 'min_child_samples': 84, 'subsample': 0.8630584672731285, 'colsample_bytree': 0.9623334850361444, 'reg_alpha': 0.0003638847310331648, 'reg_lambda': 0.001458917648637202}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:47:10,483] Trial 138 finished with value: 0.8612488186085127 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 981, 'learning_rate': 0.01349204508714838, 'num_leaves': 76, 'max_depth': 9, 'min_child_samples': 76, 'subsample': 0.8725112455554503, 'colsample_bytree': 0.9880167839701685, 'reg_alpha': 0.00010028859540954515, 'reg_lambda': 0.00124777340766497}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:48:05,009] Trial 139 finished with value: 0.8639881524546386 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 997, 'learning_rate': 0.01209453092257069, 'num_leaves': 67, 'max_depth': 9, 'min_child_samples': 83, 'subsample': 0.9058806360042566, 'colsample_bytree': 0.9483973942838219, 'reg_alpha': 0.0005341896622219756, 'reg_lambda': 0.0017156256342026211}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:48:54,251] Trial 140 finished with value: 0.8578477836100062 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 918, 'learning_rate': 0.01083524348555544, 'num_leaves': 75, 'max_depth': 8, 'min_child_samples': 87, 'subsample': 0.8827455016133164, 'colsample_bytree': 0.9450288739205613, 'reg_alpha': 0.00013188559449940518, 'reg_lambda': 0.0010649776354951406}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:49:47,084] Trial 141 finished with value: 0.8627964770102627 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 941, 'learning_rate': 0.01333380503605217, 'num_leaves': 77, 'max_depth': 9, 'min_child_samples': 89, 'subsample': 0.8455413585957229, 'colsample_bytree': 0.9579273887598353, 'reg_alpha': 0.0002467442478476232, 'reg_lambda': 0.00217737382789615}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:50:31,205] Trial 142 finished with value: 0.8603815049273523 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 735, 'learning_rate': 0.012874329360525825, 'num_leaves': 69, 'max_depth': 9, 'min_child_samples': 89, 'subsample': 0.8561435773894781, 'colsample_bytree': 0.9772983947085507, 'reg_alpha': 0.00022145770455140847, 'reg_lambda': 0.001299809134717416}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:51:27,830] Trial 143 finished with value: 0.8604222160305753 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 951, 'learning_rate': 0.013780668354572713, 'num_leaves': 64, 'max_depth': 9, 'min_child_samples': 85, 'subsample': 0.8392964424087971, 'colsample_bytree': 0.9382667607674161, 'reg_alpha': 0.00031874907550599166, 'reg_lambda': 0.0015433220845468018}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:51:32,376] Trial 144 finished with value: 0.11553623301742776 and parameters: {'resampling': 'none', 'classifier': 'LogisticRegression', 'C': 0.019327565377124812, 'lr_class_weight': True}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:52:28,879] Trial 145 finished with value: 0.8545630486185339 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 978, 'learning_rate': 0.012254839385841973, 'num_leaves': 79, 'max_depth': 9, 'min_child_samples': 78, 'subsample': 0.8613537248317846, 'colsample_bytree': 0.9657160233910983, 'reg_alpha': 0.0004038744888399483, 'reg_lambda': 0.0020081096343420543}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:53:23,668] Trial 146 finished with value: 0.8616143521368285 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 947, 'learning_rate': 0.011438228510442456, 'num_leaves': 73, 'max_depth': 9, 'min_child_samples': 86, 'subsample': 0.8973043157937367, 'colsample_bytree': 0.948851900545714, 'reg_alpha': 0.0006166340532219459, 'reg_lambda': 0.0017982992117882791}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:54:15,373] Trial 147 finished with value: 0.8561230934623395 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 987, 'learning_rate': 0.013125705118268853, 'num_leaves': 78, 'max_depth': 9, 'min_child_samples': 72, 'subsample': 0.8721125120786354, 'colsample_bytree': 0.9338798890722564, 'reg_alpha': 0.00022413203105402138, 'reg_lambda': 0.002701066684651599}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:55:12,063] Trial 148 finished with value: 0.8643875562722569 and parameters: {'resampling': 'none', 'classifier': 'LightGBM', 'n_estimators': 965, 'learning_rate': 0.014194626257242948, 'num_leaves': 61, 'max_depth': 9, 'min_child_samples': 82, 'subsample': 0.8498395635928379, 'colsample_bytree': 0.9708321416328153, 'reg_alpha': 0.0001502203412169833, 'reg_lambda': 0.001192701092206095}. Best is trial 130 with value: 0.8702454099919538.\n",
      "[I 2025-11-15 20:55:16,602] Trial 149 finished with value: 0.08633411964254271 and parameters: {'resampling': 'under', 'classifier': 'LightGBM', 'n_estimators': 969, 'learning_rate': 0.014244608344169003, 'num_leaves': 62, 'max_depth': 9, 'min_child_samples': 82, 'subsample': 0.839393773337345, 'colsample_bytree': 0.9845953851733502, 'reg_alpha': 0.00018229059738260667, 'reg_lambda': 0.001011025010990454}. Best is trial 130 with value: 0.8702454099919538.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-score: 0.8702\n",
      "Best hyperparameters:\n",
      "  resampling: none\n",
      "  classifier: LightGBM\n",
      "  n_estimators: 984\n",
      "  learning_rate: 0.012884579931656037\n",
      "  num_leaves: 68\n",
      "  max_depth: 9\n",
      "  min_child_samples: 86\n",
      "  subsample: 0.8515735476743733\n",
      "  colsample_bytree: 0.9614950229666329\n",
      "  reg_alpha: 0.00021881931021067107\n",
      "  reg_lambda: 0.002003625697370366\n"
     ]
    }
   ],
   "source": [
    "# WE are maximizing F1\n",
    "study = optuna.create_study(direction='maximize',\n",
    "                             study_name='Fraud_detection_optimization')\n",
    "# Let's run for 150 trials\n",
    "study.optimize(objective, n_trials=150)\n",
    "print(f\"Best F1-score: {study.best_value:.4f}\")\n",
    "print(\"Best hyperparameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e5192",
   "metadata": {},
   "source": [
    "#### **7. Final Model Training and Threshold Tuning**\n",
    "\n",
    "Now that Optuna has found the best pipeline configuration, we train it on the full training set and then perform the final, crucial step: tuning the decision threshold on the test set to meet our business goal (e.g., achieve 95% recall)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511dd6b7",
   "metadata": {},
   "source": [
    "**Build and Train the Final pipeline with the best parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcd6c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n",
      "LightGBM\n",
      "[LightGBM] [Info] Number of positive: 394, number of negative: 227451\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7650\n",
      "[LightGBM] [Info] Number of data points in the train set: 227845, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001729 -> initscore=-6.358339\n",
      "[LightGBM] [Info] Start training from score -6.358339\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;resampler&#x27;, &#x27;passthrough&#x27;),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LGBMClassifier(colsample_bytree=0.9614950229666329,\n",
       "                                is_unbalance=True,\n",
       "                                learning_rate=0.012884579931656037, max_depth=9,\n",
       "                                metric=&#x27;binary_logloss&#x27;, min_child_samples=86,\n",
       "                                n_estimators=984, n_jobs=-1, num_leaves=68,\n",
       "                                objective=&#x27;binary&#x27;, random_state=42,\n",
       "                                reg_alpha=0.00021881931021067107,\n",
       "                                reg_lambda=0.002003625697370366,\n",
       "                                subsample=0.8515735476743733))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">steps&nbsp;</td>\n",
       "            <td class=\"value\">[(&#x27;resampler&#x27;, ...), (&#x27;classifier&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">transform_input&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">memory&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>passthrough</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"resampler__\"><pre>passthrough</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"classifier__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves&nbsp;</td>\n",
       "            <td class=\"value\">68</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">9</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">0.012884579931656037</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">984</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin&nbsp;</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples&nbsp;</td>\n",
       "            <td class=\"value\">86</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">0.8515735476743733</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">0.9614950229666329</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.00021881931021067107</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">0.002003625697370366</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary_logloss&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('is_unbalance',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">is_unbalance&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('resampler', 'passthrough'),\n",
       "                ('classifier',\n",
       "                 LGBMClassifier(colsample_bytree=0.9614950229666329,\n",
       "                                is_unbalance=True,\n",
       "                                learning_rate=0.012884579931656037, max_depth=9,\n",
       "                                metric='binary_logloss', min_child_samples=86,\n",
       "                                n_estimators=984, n_jobs=-1, num_leaves=68,\n",
       "                                objective='binary', random_state=42,\n",
       "                                reg_alpha=0.00021881931021067107,\n",
       "                                reg_lambda=0.002003625697370366,\n",
       "                                subsample=0.8515735476743733))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "final_resampling_Strategy = best_params.pop('resampling')\n",
    "print(final_resampling_Strategy)\n",
    "final_classifier_name = best_params.pop('classifier')\n",
    "print(final_classifier_name)\n",
    "if final_resampling_Strategy == 'smote':\n",
    "    final_resampler = SMOTE(random_state=42)\n",
    "elif final_resampling_Strategy == 'under':\n",
    "    final_resampler = RandomUnderSampler(random_state=42)\n",
    "else:\n",
    "    final_resampler = 'passthrough'\n",
    "\n",
    "if final_classifier_name == 'LogisticRegression':\n",
    "    use_class_weight = best_params.pop('lr_class_weight', None)\n",
    "    print(use_class_weight)\n",
    "    if use_class_weight:\n",
    "        best_params['class_weight'] = 'balanced'\n",
    "    final_classifier = LogisticRegression(random_state=42,\n",
    "                                          solver='liblinear', **best_params)\n",
    "else:\n",
    "    # Remove any irrelevant params from the dict before passing to LGBM\n",
    "    lgbm_keys = ['objective', 'metric', 'n_estimators', 'learning_rate', 'num_leaves', 'max_depth', 'min_child_samples', 'subsample', 'colsample_bytree', 'reg_alpha', 'reg_lambda', 'is_unbalance']\n",
    "    \n",
    "    lgbm_params = {k:v for k,v in best_params.items() if k in lgbm_keys}\n",
    "    final_classifier = lgb.LGBMClassifier(objective='binary',\n",
    "                                          metric='binary_logloss',\n",
    "                                          is_unbalance = True,\n",
    "                                          n_jobs=-1,\n",
    "                                          random_state=42,\n",
    "                                          **lgbm_params)\n",
    "    final_pipeline = ImbPipeline(steps=[\n",
    "    ('resampler', final_resampler),\n",
    "    ('classifier', final_classifier)\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da3afe",
   "metadata": {},
   "source": [
    "**Threshold Tuning**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "651d342b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_recall_curve, recall_score, precision_score, f1_score\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Get the predicted probabilities for the positive class (Fraud)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m y_proba_final = \u001b[43mfinal_pipeline\u001b[49m.predict_proba(X_test)[:, \u001b[32m1\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Calculate precision and recall for all possible thresholds\u001b[39;00m\n\u001b[32m      7\u001b[39m precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba_final)\n",
      "\u001b[31mNameError\u001b[39m: name 'final_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, recall_score, precision_score, f1_score\n",
    "\n",
    "# Get the predicted probabilities for the positive class (Fraud)\n",
    "y_proba_final = final_pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate precision and recall for all possible thresholds\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba_final)\n",
    "\n",
    "# Find the threshold that gives us at least 95% recall\n",
    "target_recall = 0.95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef84e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
