{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d309cb",
   "metadata": {},
   "source": [
    "### **Chunk 7: Cross-Validation & Hyperparameter Tuning**\n",
    "\n",
    "#### **1. Concept Introduction**\n",
    "\n",
    "-   **Hyperparameters vs. Parameters**: Model **parameters** are learned from the data during `.fit()` (e.g., the coefficients in `LinearRegression`). Model **hyperparameters** are settings you choose *before* training (e.g., the number of trees in a `RandomForest`).\n",
    "\n",
    "-   **The Problem with `train_test_split` for Tuning**: How do you pick the best hyperparameter? You could try several values, train each on `X_train`, and see which performs best on `X_test`. **This is a trap!** By using `X_test` to choose your hyperparameter, you have implicitly leaked information from the test set into your model selection process. Your final performance estimate will be overly optimistic. The test set must be kept in a vault, untouched until the very end.\n",
    "\n",
    "-   **Cross-Validation (CV)**: The solution is to create a *validation set* out of the training set. The most robust way to do this is **K-Fold Cross-Validation**.\n",
    "    1.  You split the *training data* into K equal-sized \"folds\" (e.g., K=5).\n",
    "    2.  You train your model on K-1 folds and evaluate it on the held-out fold.\n",
    "    3.  You repeat this K times, with each fold getting its turn as the validation set.\n",
    "    4.  The final performance is the average of the K scores. This gives a much more stable and reliable estimate of your model's performance on unseen data.\n",
    "    5.  **`StratifiedKFold`** is essential for classification. It ensures that the class distribution in each fold is the same as in the overall training set, which is critical for imbalanced datasets.\n",
    "\n",
    "-   **Hyperparameter Tuning Tools**:\n",
    "    1.  **`GridSearchCV`**: The brute-force method. You define a \"grid\" of hyperparameters you want to test (e.g., `n_estimators: [100, 200, 300]`, `max_depth: [5, 10, 15]`). It then uses cross-validation to exhaustively train and evaluate a model for *every single combination* of these parameters. It's thorough but can be very slow.\n",
    "    2.  **`RandomizedSearchCV`**: A smarter, faster alternative. Instead of trying every combination, it samples a fixed number of random combinations from the grid. This is often more efficient because not all hyperparameters are equally important.\n",
    "    3.  **Optuna (The Modern Standard)**: This is where we level up. Optuna is an advanced hyperparameter optimization framework that uses intelligent search strategies (like Bayesian optimization) to find the best parameters. Instead of searching blindly, it learns from past trials. If it sees that high values of a certain parameter are performing poorly, it will stop exploring that region and focus on more promising areas. This makes it vastly more efficient and effective than grid or random search. We will use Optuna as our primary tool.\n",
    "\n",
    "#### **2. Dataset EDA: Credit Approval Dataset**\n",
    "\n",
    "This dataset from the UCI repository concerns credit card applications. Due to confidentiality, all feature names have been anonymized (A1, A2, etc.). It's a great real-world example with mixed data types and a slightly imbalanced target, making it perfect for a tuned pipeline. The goal is to predict whether an application was approved (+) or rejected (-).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e57122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2251d4",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe39069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "A1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "A3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "A4",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A5",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A6",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A7",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A8",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "A9",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A10",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A11",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "A12",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A13",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "A14",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "A15",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "class",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "08b40e72-81cc-4398-b4b7-15441b57307e",
       "rows": [
        [
         "0",
         "b",
         "30.83",
         "0.0",
         "u",
         "g",
         "w",
         "v",
         "1.25",
         "t",
         "t",
         "1",
         "f",
         "g",
         "202.0",
         "0",
         "+"
        ],
        [
         "1",
         "a",
         "58.67",
         "4.46",
         "u",
         "g",
         "q",
         "h",
         "3.04",
         "t",
         "t",
         "6",
         "f",
         "g",
         "43.0",
         "560",
         "+"
        ],
        [
         "2",
         "a",
         "24.5",
         "0.5",
         "u",
         "g",
         "q",
         "h",
         "1.5",
         "t",
         "f",
         "0",
         "f",
         "g",
         "280.0",
         "824",
         "+"
        ],
        [
         "3",
         "b",
         "27.83",
         "1.54",
         "u",
         "g",
         "w",
         "v",
         "3.75",
         "t",
         "t",
         "5",
         "t",
         "g",
         "100.0",
         "3",
         "+"
        ],
        [
         "4",
         "b",
         "20.17",
         "5.625",
         "u",
         "g",
         "w",
         "v",
         "1.71",
         "t",
         "f",
         "0",
         "f",
         "s",
         "120.0",
         "0",
         "+"
        ]
       ],
       "shape": {
        "columns": 16,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>202.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>43.0</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>280.0</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 class\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  202.0    0     +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g   43.0  560     +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  280.0  824     +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  100.0    3     +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  120.0    0     +"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset has no header and uses `?` for missing values\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data'\n",
    "col_names = [f'A{i}' for i in range(1, 16)] + ['class']\n",
    "df = pd.read_csv(url, header = None, names=col_names,\n",
    "                 na_values='?')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc22eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A1      678 non-null    object \n",
      " 1   A2      678 non-null    float64\n",
      " 2   A3      690 non-null    float64\n",
      " 3   A4      684 non-null    object \n",
      " 4   A5      684 non-null    object \n",
      " 5   A6      681 non-null    object \n",
      " 6   A7      681 non-null    object \n",
      " 7   A8      690 non-null    float64\n",
      " 8   A9      690 non-null    object \n",
      " 9   A10     690 non-null    object \n",
      " 10  A11     690 non-null    int64  \n",
      " 11  A12     690 non-null    object \n",
      " 12  A13     690 non-null    object \n",
      " 13  A14     677 non-null    float64\n",
      " 14  A15     690 non-null    int64  \n",
      " 15  class   690 non-null    object \n",
      "dtypes: float64(4), int64(2), object(10)\n",
      "memory usage: 86.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd2c7d",
   "metadata": {},
   "source": [
    "**Data Cleaning and Type conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49e299d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    +\n",
      "1    +\n",
      "2    +\n",
      "Name: class, dtype: object\n",
      "Unique values in class : ['+' '-']\n",
      "\n",
      "ok great we can just convert this to 0 and 1\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# The class or 'y' label is object. Let's see it\n",
    "print(df['class'].head(3))\n",
    "print(f\"Unique values in class : {np.unique(df['class'])}\")\n",
    "print(\"\\nok great we can just convert this to 0 and 1\")\n",
    "df['class'] = (df['class'] == '+').astype(int) # Convert target to 0/1\n",
    "print(df['class'].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d72f3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf647b86",
   "metadata": {},
   "source": [
    "**Missing Values check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59794ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ad0ed03b-9af6-460e-be25-7792a6c8508f",
       "rows": [
        [
         "A1",
         "12"
        ],
        [
         "A2",
         "12"
        ],
        [
         "A3",
         "0"
        ],
        [
         "A4",
         "6"
        ],
        [
         "A5",
         "6"
        ],
        [
         "A6",
         "9"
        ],
        [
         "A7",
         "9"
        ],
        [
         "A8",
         "0"
        ],
        [
         "A9",
         "0"
        ],
        [
         "A10",
         "0"
        ],
        [
         "A11",
         "0"
        ],
        [
         "A12",
         "0"
        ],
        [
         "A13",
         "0"
        ],
        [
         "A14",
         "13"
        ],
        [
         "A15",
         "0"
        ],
        [
         "class",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 16
       }
      },
      "text/plain": [
       "A1       12\n",
       "A2       12\n",
       "A3        0\n",
       "A4        6\n",
       "A5        6\n",
       "A6        9\n",
       "A7        9\n",
       "A8        0\n",
       "A9        0\n",
       "A10       0\n",
       "A11       0\n",
       "A12       0\n",
       "A13       0\n",
       "A14      13\n",
       "A15       0\n",
       "class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7fc320",
   "metadata": {},
   "source": [
    "**Target Variable Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef626a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable Distribution\n",
      "class\n",
      "0    0.555072\n",
      "1    0.444928\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAGHCAYAAAAdnkAlAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOlhJREFUeJzt3Qd4VHXe/v9PCAtEs4DUBWRBUXqESAQRVLAhyCpFRVBZiqIriPsDhAUsiCAKi4UmINgAQdEVFV1XsaColCdIQhGWIr2LoEjTMP/r/v6fM8/MkEAScpwJeb+ua65kzpk5c+bU+3zLmbhAIBAwAACAPFYorycIAABAyAAAAL6hJAMAAPiCkAEAAHxByAAAAL4gZAAAAF8QMgAAgC8IGQAAwBeEjDNELNxTLRbm4UzEcgXbD/IrQsbv4M4777QaNWoEHzVr1rTk5GRr166dvfrqq/bbb7+Fvf6qq66yf/zjH9me/ieffGIDBgw45es0TU07t5+TlZ9++sn69+9v//M//xP2nfWIFVrG+q5a7hdffLEtXLjQYkHkcopcJxMmTLCpU6dGae5iU3a3rZ9//tmuvvpqW79+fXDYggULrH379lavXj23rLVscxriFi1aFLY/e4+6devaFVdc4faFPXv25Gqa+puXZs+ebU899VSeTCvy+JEbvXv3Pu1jTt++fd2yevHFF60gWhSxrXzzzTd200032a+//mqxqHC0Z6CgqF27tj366KPu/4yMDDtw4IB98cUXNmLECHdyfvbZZ61Qof8/840bN84SExOzPe2XX345W6+77777rHPnzpbXvvvuO3vnnXfcwdvjfddY8eWXX9rbb7/tlsFll13m1kcsilz3zz33nPXq1Suq85RfDR8+3J0Uq1Wr5p4vW7bM7r33XmvZsqU98MADlpqaaqNGjXL7Y48ePXI8/UceecTq1KkTfP7LL7+4aU6ePNm+//57d4LPLk3n9ddftwsuuMDy0vPPP28NGza0aDt+/Lg71v3nP/+xtm3b5no6Co7z5s2z6tWru+XVtWtXi4uLs4KscePGVqlSJXdBou061hAyfic6cdSvXz9smA6A559/vjsYzp0712688UY33K8T4J///Gf7veT1wfJ07d+/3/1V6VHlypUtVsVq+MlvVq5cae+9957Nnz8/OGzs2LFWq1YtFyxEpQ4q4Zo4caIL38WKFcvxNh65Tzdp0sSOHTtmL7zwgq1bty7b+0Fmx4czxerVq23YsGG2fPnyHC/jSDpOyuDBg+2vf/2rK5HUSbag+9vf/madOnWyjh07Wrly5SyWUF0SZXfccYeVL1/eZs2alWWRuRdALrroIrv00kutX79+tmvXLjdOxcaLFy92D68IzStO0zSbN2/uqge++uqrTIs7VcSmA8All1xiKSkprtpl3759Jy2aDi2u08MrHdFf77WR7zt69KiNHz/err/+ektKSrLrrrvOXfHpCif0s3Tw0PBmzZq51912222Wnp5+0mWoK9EZM2bYX/7yF7eM9N5//vOf7jNF39tbntdcc81Ji9o3bNjgSg509adlcs899wSL27du3eq+90svveS+h4rc33rrLTfuv//9r3utlrUePXv2tC1btoRNe/v27W7aDRo0cCcjTSdS6LrXZ3mlG97/mTly5IiNHj3aLVMV2evzdYWnEiaPpqnv/eabb7ptQtVGOkjrBOD517/+5T4nLS3NXW1qWWqZfvjhh8HXnGwZ6CTSvXt3a9SokZsHlRqsXbvWjdO60PeOLLrXSV7btLbB7H6X7Jg0aZKbbpkyZdxznfi1rV577bVhr2vRokWwBCJ029ayyK3ixYu7v6FX2KfaPjKrLsnONrV79263z+pEq3Wq48m3334b3Ja2bdvmSvA0ba07bzvs06eP28a1/rQdrFq1Kmy6KmkdOHBgcD9QMAvdV3NC86d9VCUPpUuXzvQ1mtfsVIFpW9N31bqtUqVK2HHTo+loe1d4VKmltjuVYGpZhAZOfeZnn30W3I5vvfXWsOWf1XFU9FcndU1b27uqcHbs2OHG7dy504XZ6dOnh82XjqsqsfJKnrU8dazTNqltXdvitGnTTvg++nyN0/6o9av1F0nHyooVK2Z6TIk2Qka0V0ChQm6n0Yk0sm2G6OCnOl4ddHV1pB1f6V0btVctoatfPbQThxbf6uSkHVzFujoAZebf//63u+p78skn3Ws///xzu/vuu91BITv0eZq+6G9m1SSq89YJZ8qUKXbLLbe4nV87tqqIIl+v4lS1MXnooYfs6aeftr1799r9999/0vnR56ooVgFCxcO3336728F1YNFn66+SvrdMsqrKUXDr0KGDbdy40YYMGeIOrPp8HYS9khDvAKVlNHLkSBcWVDSuMPTDDz+4k6hKpnQy0FWFhsmhQ4fcAUInjscff9wefvhhV5zunRAyo/UpN998c/D/zGj70MFXRf6qp9Y2opO7tpHQ9gY6UT/zzDMu6Oi7/fjjj26edKIKpROb2jJoWZ133nn297//PaxEILNloG1S31eeeOIJFxp00NVyUUgrWrSoO1BqewudJx2sNR+qU87JdzkZhYZPP/3U7TMerQ8F6qpVq4a9Vicq0ToMrbZQUD0VnSS0z3oPbSMfffSRa+ehE4KWnTftU20fkbLzHn1PPdfJ8MEHH3TrS8u5W7dubhvW87Jly9qVV17pvpOucHWi03S1z2sbVKDT99A+44VpPb/rrrvcOtcxQceGpUuX2gcffGC5oW1k5syZri1aVk62X3q0HSjItmnTxj3XXx0rtI9G0nAFRR1HHnvsMbftK3wcPnw4+BotC30/hQVVS6qURSE5MtBGHkfnzJnjlnGFChXcMUrbqPZjHTu0bv70pz+5cPb++++HTUdhXdvwDTfc4J7rGDNmzBh3AekdE7Xv6GLMo+OYlovWoapDFIa03jKj93slPTFFP/UOf91xxx3ukZWRI0cGqlevHtizZ4973rx588CAAQPc/5MmTQokJycHjh49Gnz9559/Hhg7dmzg+PHjmU5/4cKFbnrjx48P+xxNU9P26P/LLrss8MsvvwSHffzxx+69n376aZbz7k1ffzN7Hvk+za/Gz507N2w6mj8N/+9//xt8T7169QI///xz8DVvv/22e83y5cszXXZr165147WcQs2ZM8cN12fLW2+95Z5v2bIlkJUnn3wycNFFFwV2794dHLZjx45As2bN3HT0Xk1j0KBBYe/r06ePW46h8/3jjz8GGjRo4KYp06dPD9SoUcPNr2f79u2BOnXqhC3f0HUv+rwxY8ZkOc/aLrp16xZ4//33w4a/+OKL7r3ed9E09XzJkiXB1+zatSuQlJQUGDVqVNgyGjduXPA12sZuuummwC233OKeZ7UMbr755kCrVq0Cv/32W3DYgQMHAg0bNgz07t07bDsJnYcHH3wwcP311+fou5xqf/K2t1WrVgWHffvtt27YV199FfbaX3/91Q1//vnnA9nlfY/MHpdcckngH//4R+CHH37I0fYRuQ9l5z3Tpk1z21To9zx06FDguuuuC7zxxhuZbk9PP/20W+dbt24NDtNyv/rqqwP333+/e/7ZZ5+5eZk/f37wNTpGNGrUKOz4kRuR85MTI0aMcNuTdyzU/lOzZs0T1p22De1XmzdvDg5buXKl+06vvfaae659Ss91fPEcPnw40KRJk8Df//73LI+jGRkZ7jXaTkNt2rTJfeZTTz0V3Je0brZt2xZ8TadOnQLdu3d3/2/YsMGNjzxuPfPMM2797Nu3z+17jRs3Ds6P55FHHjnheBt67F63bl0gllCSEQO8K7TMGjCpqFLpu3Xr1u6qQ41EmzZt6q5GT9XgSUV2p6KEfNZZZwWfqwixcOHCtmTJEssrqsrRNJW0Q3ltUDTeozrs0IaPqkqS0CuQyGmLd3Xg0fP4+PgctdZXqZHqxXX159FViYpUtZyyWq66iteVi66EvKtafQdVP3399dfuNVpvahMTWkevK6HTrYcvUqSIu3Ju1aqVK4nRvKh4VfPsVRN4zj33XDdPHl3Z6soscl2HNszTNqbiXJW0qSojs2WgUhpdYapBpZZ5aLWBipm9daRlpCJd7wpPVShqxOeVYuTku5yMVy2g7+s5VVG/1+g6J3SFrOqnN954w5X+6LvralmlaqVKlcrR9hEpO+/R9qrvGLouEhISXGmgSgwzo54Ier32K2+6+u5qnxK6rf7hD3+wyy+/PPg+HSNC94Hfm0qh3n33XVdaqe1QPdrOPvtsV12h5R+5flW1Edr2SiW9eh66reuYpOOqR8tayyFyfwhdviphUs+h0PeJ9m3tS962rlI0lSp98L+lPyrV0/rytnWtXx33dbwNLQ3Tc+0Xeq2qblUyon0olPazzHjbu7f9xwoafsYAHVC1gZcsWfKEcdpwVW+nejzVt+l/1TOr+uFUdZih4SEroSdU0QHnnHPOcTtxXlH9rqYZegIK/Wy1GA89SEbOz8lOEpp26LRCDyD6zNBpn4qKu0NPTNldrnqfDiaZFSd7JxtvGUTSfGdW3JvTnjMqZtVBSQdeFUt78xhaxeAFtlCqI1fReajIhmN6jaYTuk2ELgMtY4332j+E0jBvHSiwqI2HqolUjK3woICiYTn9LifjfV7otvTHP/4xWMUQ6uDBg+5vTnpzeVQdorpwUTG2TsxelUVob5XsbB+RsvMevSarNg5Z0Xs2bdoUVq0aSmFe26qORZEXMZH72O9J1bg64SrU6RFJ201oCMpqW/eOF962qeNE5GtCq0Yjt3VvXFbbute2RduTAtH777/vqp60HrU9aljodCIvjkLPCd56jjxuZLUevO09J8e83wMhI8qUXnW1reQdeRL26IpCDx0AlIB1bw3VeevAprrf0xG5Q6ntg+rIQw9eke0hdGLIiRIlSrhpajqh39FrC5DZyTcn0xZdXagbV+iVjz4zJ9PWiSi00Wvo1Z/CR1YlR3qfGpipgWIk7yCm+dDB/VTLP6c2b97sGgTq4KXGjrpa03yqIawOvKG0PCIp4ESeqDRPoQdRvUbrTSeeyPYb3vfXZ2YWlrReQsOzruQ0n9rmdeBVSZ233nLyXU7GW+cKRd6BWlea+g6R60CfKV4319Ohdj8qmVE9u9p0qJtldrePSNl5j16T2VWr2k9ov8jsO+k9KiFR25fMqDRJyy+z/fV0t9XToXY62h7UNiWUgqdKdVXiFRoystrWQ3vYZfZ9MtsfQnnbclbbeujxRiW1PXr0cNucwobaJHlBwGsc/Morr7gwHUklfl6oj2y3k9V68ALU6RxP/UB1SZSpQZY2Tq/RXCQ1+tL9J7QzaQNV0Zl34y2vlXFuinpDG96FNjhVUaueq8W0l8jVWjqU1xLfk1U48uigpmmG9lIQFX+Kijxzy7sHQGQjKz3XQTIn01ZRtHpWhAYN7eBeI7iTzYO6K6pYVVe2eqi1uEqfPv74Y/catYbXCUHVCh59ju7dcDKnWrcrVqxwxas6mOkA6gUh76QcevWvxoChN6bS1ZIarEV2AdSJ0qP3qzGjlqNOQJnRlZ6+rxp1hgZSXVHpCjR0HejEp6torR8tU6/KLKff5WR0gJbQ7ValC1q/Wh+h09H2rhPv6YZ17+Svxnza1r3eMtndPiJl5z36PmoM6vXgES0/NZT2rvYjtx9NV0X+XimM99B9bvQe7cvaHvQdQrcDVVV5PSt+bzo+ahvQVb+OS6EP7VeqhtW25PW4845RoUFD25b2v9BtXdUuoeFVz3XvopN1idVyU0lCZANLrQfty7pY9Khau0yZMu6iUKWFXlWJeNWWmsfQ9aBjghqhKkiokbKqVCOPm171YSTv+3vbf6ygJON3omJZ74Sion9tXLr7oEKGDrShLeFDaSdSNYm6ZOl1ukJXLw0lao3zUrFOFrrizul9FrQD66CkqhedhNRaWr0FvB1NoUYt9VXPrPpC1deqdXUoryhaJxRdQUW2Ilc9pw4IKiLXjqDxqrtUbxnV/5/OPTX0Xk1DV48q6dGVsVqHq9hanxlar3wqXbp0cd9NoUJ17Cr+Vm8VtctQkX5WxZDqvaIW+3qPwqJOaFqv3lWt6ACjg42uuv7f//t/Lrxp2qdqK6B1qytT1RPrwBRZmqITtk5u6i2iFu86GahVvdZFZKmT18tHn6+TiZaR1ldktZt6A+hkpQOqqjYUTHTFdTLq/aGW+QoIaq2v7VRVe5oflU6E0rJQeI5sp5OT73IyWk6qftSJJnR/UEmDSgZ0wyIFd+0zagOiefeuMLWf6uSukJNVVcbJqHpT+6lO2gpdqj/PzvYRKTvv0T1f1OVR30t30tQVrLYxLXutA2/7URG+9jcFKW3jmjf91TLWe1SipHYN6iUh2vd1gtT+qpCtkiZNVyfA0Kt8PVdJUGQ7qtzQPCrEZnYs0D6p0JNV1YJ6mWg71XfQsUx0LNB+rGWjKjL1qlLJUmRbCn1n9Z7S99K2oG3M64mWGYU2df/V+7TdaF3rWO7tS6ElT9rHbrjhBtdDRNU33oWbqGus3queIupaqwCp8Kf5VKmpAob2dd2uQJ+jdaF9RecQ9dTJjNdGx+vVFDOi3fK0IFBr59AW6GpVfPHFFwduu+22wOuvvx7sJZJVC+z33nsv0LZt20D9+vVdT5O77rorsHr16uD4b775xvWAUOvmd999N9PeHln1LlFL9cGDB7tpq+X2kCFDwnqbqLeAeh+opbt6Xqh1dGpqatj01eJareHVKvqGG27ItAeAWr3rsy6//HI3ny1atAhMmTLFvTd0OZ2qJ0tmNI8TJkxwLeQ1bX0vtaI/cuRI8DXZ6V0iapl9zz33BJeHWtx77/F6VmhakVasWOGWjdaP3nvrrbcG5s2bF/Ya9Tjo27dvICUlxfVC0HJ94IEHTtq7RD0r9Hr1ugltqR7q3//+t1vuWv5NmzYN9OrVK7B48WK3nalXS+i6V+t6tY7X9qfXhS4Pbxm98847rqeIptehQ4ewZX+yZaDXqQW9thPN87333hvsORRq7969gdq1awd7neT0u5yqd4nofV5L/lAfffRRoHXr1m47ueqqqwJTp0494Ttk9f2yu02q1462A+2T2u6zs31kNs3sbFM7d+50+56Wt9apej189913YccO9VCoW7dusFePekJo2Wsb1Lq68cYbA7Nnzw6bruZ76NChrkeJPlu9iYYNGxZ2/PC2l5Ptm9ntXaLhWa1T9T7yjiuZ0fFT61LHFh0LNJ3bb7/d9cDTPqyHevyox4bH612iHhn6bO1fXbt2DVt2J1vPH374oTsmazvSMurXr5/r7RJpxYoVbhper5PInk3qyeUdt6644orAo48+6noRhVJvK31/rcN27dq5XnqZzZf2WfVUjDWEDKAAiAyYmcluEMsP0tPTA7Vq1co330XdRbXs09LSAvmJuiCre3AsyU4I9ULGmWLJkiUumCvgxhraZAA446h+W8XL+eHH5dTGwmsPkZ3eTbFC1Upqw+Q1cEX0TJkyxd00MNZuKS6EDABnJN2hUQ0CdTKMVWp3osaianOjuv7ctAOJFs2rGqJmp6s8/KO2eOoE4LVHiTVxKs6I9kwAAIAzDyUZAADgzA4Z6voW+suj6tKkW+PqhlPqbqZ+zqHUT1k37dF4dZHL7CZKAACggIcM78Y8HvVVVuhQf3f1k1ffc/UX9/rJ63cU9JPguueA+o7rzmheH28AABAbon4zLt3ZTDf/8X4DQHRzGN18Rre+1Q1JFCh0Jzbd+Uw3oNHNTXSTG+8nf/V+3TRKd10L/VGc7PxMs26ucqofGgMAAP9HzTl1HtUN9E52Z+Kohwzd+U93AAz9TQR1i9KtiL2Tv/7qdq2625lChsbffffdwdfr1qu6laqGZzdkKGCE3uIZAADkjAoIsvrJgahXl6jrjW5TrVvoRt7qOrNfgvR+i0CB5GTjs+N0fu8DAADYKc+lUSvJ0G8jPProo64vu35nIJTuOx+ZjPRcfcq9H7I52fjs8EpJlMJO9QNfAADg/+jHEFUbcKrmBlELGfpBGf0oTGY/YKX2GJGBQc+9MJLVeO9HjnJCAYOQAQBA3isczR4le/fudT1HxAsN+ull/VKexoXSc6+KRL9ol9l4/QQvAAAo4CFDP1Gsxpeef/7zn+6vftpWt9jVz4Cr9aqKYvRXP3etn6kW3RtDP2urRqCyY8cO99BwAABQwENGpUqVwp6fffbZ7m+VKlVcI87Ro0fb8OHD7bbbbrNZs2a5dhrqtiodO3a0O++80+rXr+/aVOh1zZo1y3bPEgAA4L+Y7GKRmJhokyZNCpZWqGvq5MmTgz/EoyqWoUOH2vjx413gKFGihI0YMSLasw0AAEIU2B9IU8tY3XdDpSE0/AQAIO/PoTFZkgEAAPI/QgYAAPAFIQMAAPiCkAEAAHxByAAAAL4gZPgk4/hxvyYNxAy2cwAnE/Wfej9TxRcqZA+99qV9v/tAtGcF8MV55UrYsE4n/vYQAHgIGT5SwFi9bZ+fHwEAQMyiugQAAPiCkAEAAHxByAAAAL4gZAAAAF8QMgAAgC8IGQAAwBeEDAAA4AtCBgAA8AUhAwAA+IKQAQAAfEHIAAAAviBkAAAAXxAyAACALwgZAACAkAEAAPIPSjIAAIAvCBkAAMAXhAwAAHDmhYxNmzZZ9+7dLTk52Zo1a2ZTpkwJjhs2bJjVqFEj7DF9+vTg+Llz59o111xj9erVs549e9q+ffui9C0AAEBmCluUHD9+3Hr06GFJSUn29ttvu8DRp08fK1++vP3lL3+x9evXW9++fa1t27bB9yQmJrq/6enpNnjwYHvsscesZs2aNnz4cBs4cKBNmjQpWl8HAADESknG3r17rVatWjZkyBCrWrWqXXnllda4cWNLTU114xUyateubWXLlg0+EhIS3DiVaLRs2dLatGnjQsbIkSNt/vz5tmXLlmh9HQAAECsho1y5cvbss8+60olAIODCxZIlS6xhw4Z28OBB27VrlwsfmUlLS7OUlJTg8woVKljFihXdcAAAUMCrS0JdddVVtn37dmvevLm1aNHCVqxYYXFxcTZx4kT74osvrGTJkta1a9dg1cnu3btdSAlVunRp27lzZ44/OyMjw/wQHx/vy3SBWOPXPgQg/+/3MREyxowZ46pPVHUyYsQIq1OnjgsZ559/vt1xxx2uhOPhhx92pR7XXnutHTlyxIoUKRI2DT0/duxYjj97+fLlltdUraOqHqAgWLNmjR0+fDjaswEgBsVEyFDjTzl69Kj169fPli5d6ko1VIIhanexceNGmzlzpgsZRYsWPSFQ6LnXZiOnn02pA5B76vkFoOCVZCzPxkV61EKGSi6WLVvmuqF6LrjgAvv1119dm4xSpUqFvV6lGgsXLnT/qweK3h85PTUOzSkFDEIGkHvsPwBiruHn1q1brVevXq6Bp0dtMRQupk2bZl26dAl7/erVq13QEN0bw+uFIjt27HAPDQcAAAU8ZKiaQm0vBg0aZOvWrXNdUEeNGmX33nuvqypRO4ypU6fa5s2b7bXXXrM5c+ZYt27d3Hs7duxo77zzjs2ePduFj/79+7ubeVWuXDlaXwcAAMRKdYmKWCdMmGCPP/64dejQwbWnuPPOO61z586u0edzzz3nGoTqb6VKlWz06NHuzqCiv0OHDnXjDxw4YE2aNHHTAQAAsSOqDT/VtmLcuHGZjlNbjdD2GpHatWvnHgAAIDbxA2kAAMAXhAwAAOALQgYAAPAFIQMAAPiCkAEAAHxByAAAAL4gZAAAAF8QMgAAgC8IGQAAwBeEDAAA4AtCBgAA8AUhAwAA+IKQAQAAfEHIAAAAviBkAAAAXxAyAACALwgZAADAF4QMAADgC0IGAADwBSEDAAD4gpABAAB8QcgAAAC+IGQAAABfEDIAAIAvCBkAAMAXhAwAAHDmhYxNmzZZ9+7dLTk52Zo1a2ZTpkwJjtuyZYt16dLF6tevb61atbIFCxaEvffrr7+21q1bW7169axz587u9QCQHRnHj7OgcMbLiIHtvHC0Pvj48ePWo0cPS0pKsrffftsFjj59+lj58uVdeOjZs6dVr17d3nrrLZs3b5716tXLPvjgA6tYsaJt377djb///vvt8ssvt/Hjx9t9991n7777rsXFxUXrKwHIJ+ILFbKHXvvSvt99INqzAvjivHIlbFiny63Ahoy9e/darVq1bMiQIZaYmGhVq1a1xo0bW2pqqpUpU8aVTMyaNcvOOussq1atmn3zzTcucChYzJ492+rWrWvdunVz0xoxYoQ1adLEFi9ebI0aNYrWVwKQjyhgrN62L9qzAZzRolZdUq5cOXv22WddwAgEAi5cLFmyxBo2bGhpaWlWu3ZtFzA8DRo0sGXLlrn/NT4lJSU4LiEhwerUqRMcDwAArOCWZIS66qqrXBVI8+bNrUWLFvbEE0+4EBKqdOnStnPnTvf/nj17Tjo+JzIyMswP8fHxvkwXiDV+7UN+Yv9EQZHh0/6Z3enGRMgYM2aMqz5R1YmqPg4fPmxFihQJe42eHzt2zP1/qvE5sXz5cstrKllRSQxQEKxZs8btk/kF+ycKkjVR3j9jImSo8accPXrU+vXrZ+3btz9hoShAFCtWzP1ftGjREwKFnhcvXjxXn81VDZB7NWrUYPEBBWz/zMjIyNZFelQbfqoNxTXXXBMcdsEFF9ivv/5qZcuWtQ0bNpzweq+KRD1Q9DyzhqQ5pYBByAByj/0HiF3xUa66j1rDz61bt7puqbt27QoOW7FihZUqVco18ly5cqUdOXIkOE4NQ3VPDNFfPfeo1GPVqlXB8QAAIPqiFjJUTaEeIYMGDbJ169bZ/PnzbdSoUXbvvfe6HiYVKlSwgQMH2tq1a23y5MmWnp5uN998s3uvqlOWLl3qhmu8XnfuuefSfRUAgBhSKJpFOBMmTHCNsDp06GCDBw+2O++809290xunXiTt2rVzN9nSDbd0Iy5RoBg7dqy7b4aCx/79+914bsQFAEDsiGrDT7WtGDduXKbjqlSpYtOnT8/yvVdeeaV7AACA2MQPpAEAAF8QMgAAgC8IGQAAwBeEDAAA4AtCBgAA8AUhAwAA+IKQAQAACBkAACD/oCQDAAD4gpABAAB8QcgAAAC+IGQAAABfEDIAAIAvCBkAAMAXhAwAAOALQgYAAPAFIQMAAPiCkAEAAHxByAAAAL4gZAAAAF8QMgAAgC8IGQAAwBeEDAAA4AtCBgAA8AUhAwAA+IKQAQAAzryQsWvXLuvdu7c1bNjQLr/8chsxYoQdPXrUjRs2bJjVqFEj7DF9+vTge+fOnWvXXHON1atXz3r27Gn79u2L4jcBAACRCluUBAIBFzCKFy9uM2bMsAMHDtigQYOsUKFCNmDAAFu/fr317dvX2rZtG3xPYmKi+5uenm6DBw+2xx57zGrWrGnDhw+3gQMH2qRJk6L1dQAAQKyUZGzYsMGWLVvmSi8uvPBCS0lJcaFDJRSikFG7dm0rW7Zs8JGQkODGqUSjZcuW1qZNGxcyRo4cafPnz7ctW7ZE6+sAAIBYCRkKDVOmTLEyZcqEDT948KB7qCqlatWqmb43LS3NhRJPhQoVrGLFim44AAAo4NUlqiZROwzP8ePHXQnFpZde6kox4uLibOLEifbFF19YyZIlrWvXrsGqk927d1u5cuXCple6dGnbuXNnjucjIyPD/BAfH+/LdIFY49c+5Cf2TxQUGT7tn9mdbtRCRqRRo0bZqlWr7M0337SVK1e6kHH++efbHXfcYUuWLLGHH37Ytcm49tpr7ciRI1akSJGw9+v5sWPHcvy5y5cvt7ymah1V9QAFwZo1a+zw4cOWX7B/oiBZE+X9s3CsBIxXXnnFnnnmGatevbpro9G8eXNXgiFqd7Fx40abOXOmCxlFixY9IVDouddmIyeSkpK4qgFOg3p+AShY+2dGRka2LtKjHjIef/xxFx4UNFq0aOGGqRTDCxgelWosXLjQ/V++fHnbu3dv2Hg9VzuP3BSbUnQK5B77DxC74qNcdR/V+2SMGzfOZs2aZU8//bTdcMMNweHPPfecdenSJey1q1evdkFDdG+M1NTU4LgdO3a4h4YDAIDYELWQocadEyZMsLvvvtsaNGhge/bsCT5UVaJ2GFOnTrXNmzfba6+9ZnPmzLFu3bq593bs2NHeeecdmz17tgsf/fv3t2bNmlnlypWj9XUAAECsVJd88sknrk7n+eefd4/IhioqzRgzZoz7W6lSJRs9erQlJye78fo7dOhQN1438WrSpImrdgEAALEjaiGjR48e7pEV3TJcj6y0a9fOPQAAQGziB9IAAIAvCBkAAMAXhAwAAOALQgYAAPAFIQMAAPiCkAEAAHxByAAAAL4gZAAAAF8QMgAAgC8IGQAAwBeEDAAA4AtCBgAA8AUhAwAA+IKQAQAAfEHIAAAAviBkAACA2AkZnTt3tp9++umE4fv27bN27drlxXwBAIB8rnB2X/jFF19Yenq6+3/JkiU2ceJEO+uss8Jes2nTJtu2bVvezyUAADhzQ8Z5551nU6ZMsUAg4B5Lly61P/zhD8HxcXFxLnQMHz7cr3kFAABnYsioXLmyvfrqq+7/gQMH2uDBgy0xMdHPeQMAAAUhZIQaMWKE+7tnzx777bffXMlGqIoVK+bN3AEAgIIVMr766it7+OGHbceOHe65QoaqS7y/3333XV7PJwAAKAghY+jQoXbRRRfZ888/T5UJAADIu5Cxc+dO1whU7TQAAADy7D4ZKSkplpqampu3AgCAAiJXJRmXXHKJPfbYY/b5559blSpVwrqySq9evfJq/gAAQEFr+Fm3bl374Ycf3COUGn4CAADkKmRMmzYtT5bcrl273M27Fi5caEWLFrVWrVpZnz593P9btmxxPViWLVvmusQOGjTImjZtGnzv119/bU888YR7Xb169dx0aCMCAEA+Dxlz5sw56fg2bdqcchrq7tq7d28rXry4zZgxww4cOOCCRKFChax///7Ws2dPq169ur311ls2b948VwXzwQcfuMCxfft2N/7++++3yy+/3MaPH2/33Xefvfvuu5SkAACQn0PGmDFjwp5nZGS4apPChQu7rq3ZCRkbNmxwpRSqeilTpowbptDx1FNP2RVXXOFKKGbNmuVuVV6tWjX75ptvXOBQsJg9e7arrunWrVvw5mBNmjSxxYsXW6NGjXLzlQAAQCyEjE8//fSEYb/88os98sgjVqNGjWxNo2zZsq4brBcwPAcPHrS0tDSrXbt22A+wNWjQwIUS0Xj1cPEkJCRYnTp13HhCBgAA+ThkZObss892pQwdO3a0Hj16nPL1qiZRVYfn+PHjNn36dLv00kvd7crLlSsX9vrSpUu7+3PIqcbnhEph/BAfH+/LdIFY49c+5Cf2TxQUGT7tn9mdbp6FDFm9erULC7kxatQoW7Vqlb355pv28ssvW5EiRcLG6/mxY8fc/4cPHz7p+JxYvny55TWVrKgkBigI1qxZ4/bJ/IL9EwXJmijvn7kKGXfeeecJDSxVXaIv06VLl1wFjFdeecWeeeYZ19hTvUv2798f9hoFiGLFirn/NT4yUOi5SkdyKikpiasa4DRkt4oUwJmzf6okIzsX6bkKGZm1e1BJQr9+/axx48Y5mtbjjz9uM2fOdEGjRYsWblj58uVt3bp1Ya/bu3dvsIpE4/U8cnytWrVyVWxK0SmQe+w/QOyKj3LVfa5CRugdPdVQU4mmRIkSOZ7OuHHjXA+Sp59+2q6//vrgcN33YvLkyXbkyJFg6YVuY67Gn9740NuaqyhIVS3caRQAgHz+2yWi6g013NQtxtVYU11IFRqya/369TZhwgS7++67XXhQY07v0bBhQ6tQoYINHDjQ1q5d6wJHenq63Xzzze697du3t6VLl7rhGq/XnXvuufQsAQAghuSqJEM3v1JPkAceeMCSk5NdY0+d9BUyVG2Snd4ln3zyiSsB0c/F6xFKbTsUQAYPHmzt2rVzv4+iz9SNuESBYuzYse6OnxquedBfbmkOAEA+DxlvvPGGu433VVddFRym9hBqK6Hh2QkZes3JXqdgoSCTlSuvvNI9AADAGVRdonYYVatWPWH4eeedZ/v27cuL+QIAAAUxZKh64sUXXwy7J4aqPqZOnepuKw4AAJCr6hI1tLz99tvdL6Hqdt6ycuVKd68K3SocAAAgVyFDP1imX0zVDbP0Q2e6OdZnn33mfjitZs2aLFUAAJC76pJp06bZkCFD7I9//KP7q5IN3QVUN+NSo1AAAIBchYyXXnrJRo8ebW3btg0OGzBggLtrp+5dAQAAkKuQ8eOPP9qf//znTHuXRN7uGwAAFEy5Chm6Q6duhhX6y25Hjx61iRMnup4nAAAAuWr4+cgjj1i3bt2sadOmwftlbN682cqUKePu1AkAAJCrkKGqkg8++MC+/PJL27hxoxUuXNiFDYWOaP/iGwAAyMchQ/QbJVdffXXezg0AADhj5PpXWAEAAE6GkAEAAHxByAAAAL4gZAAAAF8QMgAAgC8IGQAAwBeEDAAA4AtCBgAA8AUhAwAA+IKQAQAAfEHIAAAAviBkAAAAXxAyAACALwgZAADAF4QMAABw5oaMY8eOWevWrW3RokXBYcOGDbMaNWqEPaZPnx4cP3fuXLvmmmusXr161rNnT9u3b1+U5h4AAMRkyDh69Kj16dPH1q5dGzZ8/fr11rdvX1uwYEHw0b59ezcuPT3dBg8ebL169bLXX3/dfvrpJxs4cGCUvgEAAMhMYYuidevWuSARCAROGKeQ0b17dytbtuwJ41Si0bJlS2vTpo17PnLkSGvevLlt2bLFKleu/LvMOwAAiOGSjMWLF1ujRo1caUSogwcP2q5du6xq1aqZvi8tLc1SUlKCzytUqGAVK1Z0wwEAQGyIaklGp06dMh2uUoy4uDibOHGiffHFF1ayZEnr2rWrtW3b1o3fvXu3lStXLuw9pUuXtp07d+Z4HjIyMswP8fHxvkwXiDV+7UN+Yv9EQZHh0/6Z3elGNWRkZcOGDS5knH/++XbHHXfYkiVL7OGHH7bExES79tpr7ciRI1akSJGw9+i5GpDm1PLlyy2vJSQkWO3atfN8ukAsWrNmjR0+fNjyC/ZPFCRrorx/xmTIUFsLtbFQCYbUrFnTNm7caDNnznQho2jRoicECj3XwSOnkpKSuKoBToN6fgEoWPtnRkZGti7SYzJkqBTDCxgelWosXLjQ/V++fHnbu3dv2Hg9z6yRaHaKTSk6BXKP/QeIXfFRrrqPehfWzDz33HPWpUuXsGGrV692QUN0b4zU1NTguB07driHhgMAgNgQkyFDVSVqhzF16lTbvHmzvfbaazZnzhzr1q2bG9+xY0d75513bPbs2S589O/f35o1a0b3VQAAYkhMVpdcdNFFrjRjzJgx7m+lSpVs9OjRlpyc7Mbr79ChQ934AwcOWJMmTezxxx+P9mwDAIBYDBlqARtKtwzXIyvt2rVzDwAAEJtisroEAADkf4QMAADgC0IGAADwBSEDAAD4gpABAAB8QcgAAAC+IGQAAABfEDIAAIAvCBkAAMAXhAwAAOALQgYAAPAFIQMAAPiCkAEAAHxByAAAAIQMAACQf1CSAQAAfEHIAAAAviBkAAAAXxAyAACALwgZAADAF4QMAADgC0IGAADwBSEDAAD4gpABAAB8QcgAAAC+IGQAAIAzN2QcO3bMWrdubYsWLQoO27Jli3Xp0sXq169vrVq1sgULFoS95+uvv3bvqVevnnXu3Nm9HgAAxI6oh4yjR49anz59bO3atcFhgUDAevbsaWXKlLG33nrLbrrpJuvVq5dt377djddfjW/Xrp29+eabVqpUKbvvvvvc+wAAQGyIashYt26d3XrrrbZ58+aw4QsXLnQlE0OHDrVq1arZPffc40o0FDhk9uzZVrduXevWrZtdeOGFNmLECNu2bZstXrw4St8EAADEVMhQKGjUqJG9/vrrYcPT0tKsdu3adtZZZwWHNWjQwJYtWxYcn5KSEhyXkJBgderUCY4HAADRVziaH96pU6dMh+/Zs8fKlSsXNqx06dK2c+fObI3PiYyMDPNDfHy8L9MFYo1f+5Cf2D9RUGT4tH9md7pRDRlZOXz4sBUpUiRsmJ6rgWh2xufE8uXLLa+pZEUlMUBBsGbNGrdP5hfsnyhI1kR5/4zJkFG0aFHbv39/2DAFiGLFigXHRwYKPS9evHiOPyspKYmrGuA01KhRg+UHFLD9MyMjI1sX6TEZMsqXL+8ahYbau3dvsIpE4/U8cnytWrVyVWxK0SmQe+w/QOyKj3LVfdS7sGZG975YuXKlHTlyJDgsNTXVDffG67lHRUGrVq0KjgcAANEXkyGjYcOGVqFCBRs4cKC7f8bkyZMtPT3dbr75Zje+ffv2tnTpUjdc4/W6c8891/VUAQAAsaFQrBbvTJgwwfUi0Q233n33XRs/frxVrFjRjVegGDt2rLtvhoKH2m9ofFxcXLRnHQAAxFqbDLWADVWlShWbPn16lq+/8sor3QMAAMSmmCzJAAAA+R8hAwAA+IKQAQAAfEHIAAAAviBkAAAAXxAyAACALwgZAADAF4QMAADgC0IGAADwBSEDAAD4gpABAAB8QcgAAAC+IGQAAABfEDIAAIAvCBkAAMAXhAwAAOALQgYAAPAFIQMAAPiCkAEAAHxByAAAAL4gZAAAAF8QMgAAgC8IGQAAwBeEDAAA4AtCBgAA8AUhAwAA+IKQAQAACl7I+Pjjj61GjRphj969e7txq1atsltuucXq1atn7du3txUrVkR7dgEAQH4JGevWrbPmzZvbggULgo9hw4bZoUOHrEePHpaSkmL/+te/LDk52e655x43HAAAxIaYDhnr16+36tWrW9myZYOP4sWL2wcffGBFixa1/v37W7Vq1Wzw4MF29tln24cffhjtWQYAAP+rsMV4yLjssstOGJ6WlmYNGjSwuLg491x/L774Ylu2bJm1a9cuR5+RkZFhfoiPj/dlukCs8Wsf8hP7JwqKDJ/2z+xON2ZDRiAQsO+//95VkUyaNMl9oeuvv961ydizZ49dcMEFYa8vXbq0rV27Nsefs3z5cstrCQkJVrt27TyfLhCL1qxZY4cPH7b8gv0TBcmaKO+fMRsytm/f7hZMkSJF7Nlnn7WtW7e69hhHjhwJDg+l58eOHcvx5yQlJXFVA5wGNcgGULD2z4yMjGxdpMdsyKhUqZItWrTISpQo4apDatWqZcePH7cHH3zQGjZseEKg0PNixYrlqtiUolMg99h/gNgVH+Wq+5gNGVKyZMmw52rkefToUdcAdO/evWHj9LxcuXK/8xwCAIB817vkyy+/tEaNGoXVJX333XcueKjR57fffuvabYj+Ll261N0zAwAAxIaYDRm694W6qT700EO2YcMGmz9/vo0cOdLuuusu1wD0p59+suHDh7t7aeivwkjLli2jPdsAACDWQ0ZiYqJNnTrV9u3b5+7oqXthdOjQwYUMjVOPk9TUVNdlVV1aJ0+ebGeddVa0ZxsAAOSHNhkXXnihvfTSS5mOu+iii+ztt9/+3ecJAADk85IMAACQvxEyAACALwgZAADAF4QMAADgC0IGAADwBSEDAAD4gpABAAB8QcgAAAC+IGQAAABfEDIAAIAvCBkAAMAXhAwAAOALQgYAAPAFIQMAAPiCkAEAAHxByAAAAL4gZAAAAF8QMgAAgC8IGQAAwBeEDAAA4AtCBgAA8AUhAwAA+IKQAQAAfEHIAAAAviBkAAAAXxAyAACAL/J1yDh69KgNGjTIUlJSrGnTpvbiiy9Ge5YAAMD/Kmz52MiRI23FihX2yiuv2Pbt223AgAFWsWJFu/7666M9awAAFHj5NmQcOnTIZs+ebS+88ILVqVPHPdauXWszZswgZAAAEAPybXXJ6tWr7bfffrPk5OTgsAYNGlhaWpodP348qvMGAADycXXJnj177JxzzrEiRYoEh5UpU8a109i/f7+VKlXqpO8PBALu77Fjxyw+Pj7P50/TvPBPJaxIfFyeTxuIBVXKFreMjAz3yG/YP3Gmq+Lz/ulN1zuXnnEh4/Dhw2EBQ7znCg6n4pV2rFq1yqc5NPvLhWeZ6QGcoZYtW2b5FfsnznTLfof981Q1B/k2ZBQtWvSEMOE9L1as2CnfX7hwYUtKSrJChQpZXBylDQAAZJdKMBQwdC49I0NG+fLl7ccff3TtMrwvqSoUBYzixYuf8v0KF5ElIQAAIO/k24aftWrVcuEitDgoNTU1WDoBAACiK9+ejRMSEqxNmzY2ZMgQS09Pt3nz5rmbcXXu3DnaswYAAMwsLnCqpqEx3vhTIeOjjz6yxMRE6969u3Xp0iXaswUAAPJ7yAAAALEr31aXAACA2EbIAAAAviBkAAAAXxAykO/pVvKDBg2ylJQUa9q0qetlBCC26GaJrVu3tkWLFkV7VvA7yrc34wI8I0eOtBUrVtgrr7xi27dvtwEDBljFihX5NV4ghi4E+vbt634pGwULIQP52qFDh2z27Nn2wgsvWJ06ddxDB7IZM2YQMoAYsG7dOhcw6MhYMFFdgnxt9erV7tbyycnJwWENGjSwtLS0U/5wDwD/LV682Bo1amSvv/46i7sAoiQD+Zp+r+acc84J+x2aMmXKuOLZ/fv3W6lSpaI6f0BB16lTp2jPAqKIkgzka7rra+QP3XnPI3+lFwDw+yJkIF8rWrToCWHCe65f5AUARA8hA/la+fLl7ccff3TtMkKrUBQwihcvHtV5A4CCjpCBfK1WrVpWuHBhW7ZsWXBYamqqJSUlWaFCbN4AEE0chZGvJSQkWJs2bdyv8aanp9u8efPczbg6d+4c7VkDgAKP3iXI9wYOHOhCxl//+ldLTEy0+++/36677rpozxYAFHj81DsAAPAF1SUAAMAXhAwAAOALQgYAAPAFIQMAAPiCkAEAAHxByAAAAL4gZAAAAF8QMgAAgC8IGQB+d4sWLbIaNWqw5IEzHCEDAAD4gpABAAB8QcgA4KtNmzZZ9+7dLTk52Zo1a2avvvrqCa9JTU21jh07Wr169ax+/fp299132+7du924X3/91R566CFr1KiRm8a9995ru3btcuN++ukn94N4KSkpdskll1i/fv3s4MGDrFEgRhAyAPjm6NGj1q1bNzv77LPtjTfesEceecSeeeYZO3ToUPA1P//8s91zzz3WpEkTmzt3rk2dOtU2b95skydPduNnzJhhS5YssRdffNHefPNN++WXX+yJJ55w48aMGWN79uyxmTNnuvCyevVqmzBhAmsUiBH81DsA3yxYsMD27dvnQkFiYqJdeOGFrlSiUKH/u745cuSI3Xfffda1a1eLi4uzypUr23XXXWfp6elu/NatW61o0aJWqVIlK1mypD355JO2f/9+N27btm0uwJx77rmWkJBgzz33HGsTiCGUZADwzffff2/nnXeeCxie9u3bW7FixYLPy5Yta23atLGXX37Z+vfvb+3atXOlFsePH3fjO3To4EormjZt6kpF5s+fb9WqVXPjOnfubEuXLrXGjRvb3/72N1u+fLlVrVqVNQrECEIGAN8ULnzqwlK1r7jxxhtt4cKFVqdOHRs0aJAr1fCo9OPTTz+1UaNGuUDy9NNPu7ARCARcuFDoePTRR61IkSKuOmbAgAGsUSBGUF0CwDcqVVDDz8OHD7vqDHnqqadcNYrn448/thIlStikSZOCw6ZNm+ZChMyZM8cFiFatWlnLli1t2bJlrnTjhx9+cG04dL+Ntm3busf7779vAwcOZI0CMYKSDAC+URVHmTJlXAnD+vXr7ZNPPrFZs2ZZ3759g69RO4vt27fbN998Y1u2bHENPj/66CM7duxYsGHo8OHDg+Pfe+89+9Of/mTnnHOO7dy504YOHeqCx8aNG+0///mP1a5dmzUKxAhKMgD4d4ApXNj19lAQUEmDAofaXXilGqLSCfUe6d27t2v4mZSU5Ko8xo4d64LG7bff7sLEgw8+aAcOHLC6deva888/b/Hx8fbAAw+4EKL2GOqxom6sqlYBEBviAl6ZJAAAQB6iugQAAPiCkAEAAHxByAAAAL4gZAAAAF8QMgAAgC8IGQAAwBeEDAAA4AtCBgAA8AUhAwAA+IKQAQAAfEHIAAAA5of/DxogWBU7u0PpAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Target Variable Distribution\")\n",
    "print(df['class'].value_counts(normalize=True))\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='class', data=df)\n",
    "plt.title('Distribution of credit approval (0: Rejected, 1: Approved)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d55555",
   "metadata": {},
   "source": [
    "A very slight imbalance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472382ef",
   "metadata": {},
   "source": [
    "\n",
    "##### **3. Minimal Working Example: From GridSearchCV to Optuna**\n",
    "\n",
    "We'll use a RandomForestClassifier and tune its hyperparameters. First, we'll set up the pipeline just like in the last chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cef6fa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Features ['A2', 'A3', 'A8', 'A11', 'A14', 'A15']\n",
      "Categorical Features ['A1', 'A4', 'A5', 'A6', 'A7', 'A9', 'A10', 'A12', 'A13']\n"
     ]
    }
   ],
   "source": [
    "# Setup, imports, Data, splitting, and Pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.drop(['class'], axis=1)\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "numeric_features     = X.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric Features {numeric_features}\")\n",
    "print(f\"Categorical Features {categorical_features}\")\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('inputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "    ])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Now we will define the model seperately to attach it to different search methods\n",
    "model  = RandomForestClassifier(random_state=42,\n",
    "                                n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42edb02f",
   "metadata": {},
   "source": [
    "**Attempt : 1 : GridSearchCV (The Slow Way)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f249864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Grid search cv\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "\n",
      "Best parameters found: {'classifier__max_depth': 5, 'classifier__min_samples_leaf': 2, 'classifier__n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.8749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the Pipeline\n",
    "pipeline  = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', model)\n",
    "    ])\n",
    "\n",
    "# Define the parameter grid. Note the 'classifier__' prefic to target pipeline steps\n",
    "param_grid = {\n",
    "    'classifier__n_estimators':[50, 100, 200],\n",
    "    'classifier__max_depth': [5, 10, None],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Total fits = 3 * 3 * 3 * 5(CV folds) = 135 models!!!\n",
    "\n",
    "# Set up the search\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "grid_search = GridSearchCV(pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           cv = cv,\n",
    "                           scoring='accuracy',\n",
    "                           n_jobs=-1,\n",
    "                           verbose=1)\n",
    "\n",
    "# Run the search\n",
    "print(\"Running Grid search cv\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fac881",
   "metadata": {},
   "source": [
    "#### **Attempt 2: Optuna (The professional Way)**\n",
    "\n",
    "optuna requires you to define an \"objective\" function. This function takes a `trial` object, uses it to suggest hyperparameters, builds and evaluates the model, and returns the score you want to maximize or minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd29f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the optuna objective function\n",
    "def objective(trial):\n",
    "    # 1. define the hyperparmeter seach space\n",
    "    # The pipeline and preprocessorare fixed, we only tune the classifier.\n",
    "    classifier_name = trial.suggest_categorical('classifier', ['RandomForest']) # We can even test differnt models.\n",
    "    if classifier_name == 'RandomForest':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "        max_depth    = trial.suggest_int('max_depth', 3, 20)\n",
    "        min_sample_leaf  = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "\n",
    "        # Now we redefine the model inside the objhective with the suggested params\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_leaf=min_sample_leaf,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    # Create the full pipeline\n",
    "    pipeline = Pipeline(steps =[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "\n",
    "    # Evaluate the pipeline using cross-validation\n",
    "    # We use the same data and CV strategy as before for a fair comparison\n",
    "    cv = StratifiedKFold(n_splits=5,\n",
    "                         shuffle=True,\n",
    "                         random_state=42)\n",
    "    score= cross_val_score(\n",
    "        pipeline,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        n_jobs=-1,\n",
    "        cv= cv,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    accuracy = score.mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce8bbaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 18:43:40,750] A new study created in memory with name: no-name-5d331fd8-eda0-4187-bd55-433abb26e614\n",
      "[I 2025-11-13 18:43:46,890] Trial 0 finished with value: 0.8604750204750206 and parameters: {'classifier': 'RandomForest', 'n_estimators': 74, 'max_depth': 10, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8604750204750206.\n",
      "[I 2025-11-13 18:43:51,932] Trial 1 finished with value: 0.8604750204750203 and parameters: {'classifier': 'RandomForest', 'n_estimators': 217, 'max_depth': 17, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.8604750204750206.\n",
      "[I 2025-11-13 18:43:52,628] Trial 2 finished with value: 0.8622932022932023 and parameters: {'classifier': 'RandomForest', 'n_estimators': 172, 'max_depth': 12, 'min_samples_leaf': 5}. Best is trial 2 with value: 0.8622932022932023.\n",
      "[I 2025-11-13 18:43:53,537] Trial 3 finished with value: 0.8641277641277642 and parameters: {'classifier': 'RandomForest', 'n_estimators': 248, 'max_depth': 8, 'min_samples_leaf': 10}. Best is trial 3 with value: 0.8641277641277642.\n",
      "[I 2025-11-13 18:43:54,061] Trial 4 finished with value: 0.8623095823095823 and parameters: {'classifier': 'RandomForest', 'n_estimators': 112, 'max_depth': 3, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8641277641277642.\n",
      "[I 2025-11-13 18:43:54,438] Trial 5 finished with value: 0.855053235053235 and parameters: {'classifier': 'RandomForest', 'n_estimators': 87, 'max_depth': 7, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8641277641277642.\n",
      "[I 2025-11-13 18:43:55,204] Trial 6 finished with value: 0.8586404586404586 and parameters: {'classifier': 'RandomForest', 'n_estimators': 201, 'max_depth': 14, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8641277641277642.\n",
      "[I 2025-11-13 18:43:56,222] Trial 7 finished with value: 0.8695495495495497 and parameters: {'classifier': 'RandomForest', 'n_estimators': 271, 'max_depth': 4, 'min_samples_leaf': 8}. Best is trial 7 with value: 0.8695495495495497.\n",
      "[I 2025-11-13 18:43:57,211] Trial 8 finished with value: 0.8586404586404586 and parameters: {'classifier': 'RandomForest', 'n_estimators': 245, 'max_depth': 5, 'min_samples_leaf': 1}. Best is trial 7 with value: 0.8695495495495497.\n",
      "[I 2025-11-13 18:43:57,894] Trial 9 finished with value: 0.8695659295659295 and parameters: {'classifier': 'RandomForest', 'n_estimators': 129, 'max_depth': 16, 'min_samples_leaf': 9}. Best is trial 9 with value: 0.8695659295659295.\n",
      "[I 2025-11-13 18:43:58,528] Trial 10 finished with value: 0.8677641277641278 and parameters: {'classifier': 'RandomForest', 'n_estimators': 146, 'max_depth': 19, 'min_samples_leaf': 8}. Best is trial 9 with value: 0.8695659295659295.\n",
      "[I 2025-11-13 18:43:59,621] Trial 11 finished with value: 0.8713841113841113 and parameters: {'classifier': 'RandomForest', 'n_estimators': 287, 'max_depth': 16, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:00,162] Trial 12 finished with value: 0.8659459459459459 and parameters: {'classifier': 'RandomForest', 'n_estimators': 133, 'max_depth': 16, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:01,292] Trial 13 finished with value: 0.8641277641277642 and parameters: {'classifier': 'RandomForest', 'n_estimators': 297, 'max_depth': 20, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:01,576] Trial 14 finished with value: 0.8641277641277642 and parameters: {'classifier': 'RandomForest', 'n_estimators': 54, 'max_depth': 14, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:02,272] Trial 15 finished with value: 0.8623095823095823 and parameters: {'classifier': 'RandomForest', 'n_estimators': 174, 'max_depth': 17, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:02,856] Trial 16 finished with value: 0.8713841113841113 and parameters: {'classifier': 'RandomForest', 'n_estimators': 120, 'max_depth': 14, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:03,584] Trial 17 finished with value: 0.8623095823095823 and parameters: {'classifier': 'RandomForest', 'n_estimators': 199, 'max_depth': 12, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:04,055] Trial 18 finished with value: 0.8695659295659295 and parameters: {'classifier': 'RandomForest', 'n_estimators': 102, 'max_depth': 14, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:05,091] Trial 19 finished with value: 0.8622932022932023 and parameters: {'classifier': 'RandomForest', 'n_estimators': 295, 'max_depth': 10, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:05,923] Trial 20 finished with value: 0.8659623259623259 and parameters: {'classifier': 'RandomForest', 'n_estimators': 227, 'max_depth': 19, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:06,643] Trial 21 finished with value: 0.8677641277641278 and parameters: {'classifier': 'RandomForest', 'n_estimators': 138, 'max_depth': 16, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:07,260] Trial 22 finished with value: 0.8677313677313677 and parameters: {'classifier': 'RandomForest', 'n_estimators': 120, 'max_depth': 15, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:07,974] Trial 23 finished with value: 0.8677641277641278 and parameters: {'classifier': 'RandomForest', 'n_estimators': 168, 'max_depth': 18, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:08,680] Trial 24 finished with value: 0.8659459459459459 and parameters: {'classifier': 'RandomForest', 'n_estimators': 152, 'max_depth': 13, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:09,185] Trial 25 finished with value: 0.8623095823095822 and parameters: {'classifier': 'RandomForest', 'n_estimators': 97, 'max_depth': 16, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:09,749] Trial 26 finished with value: 0.8568386568386568 and parameters: {'classifier': 'RandomForest', 'n_estimators': 123, 'max_depth': 10, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:10,197] Trial 27 finished with value: 0.8605077805077805 and parameters: {'classifier': 'RandomForest', 'n_estimators': 67, 'max_depth': 15, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:10,828] Trial 28 finished with value: 0.8677641277641278 and parameters: {'classifier': 'RandomForest', 'n_estimators': 158, 'max_depth': 18, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:11,568] Trial 29 finished with value: 0.8695659295659295 and parameters: {'classifier': 'RandomForest', 'n_estimators': 192, 'max_depth': 11, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:12,022] Trial 30 finished with value: 0.8514168714168713 and parameters: {'classifier': 'RandomForest', 'n_estimators': 78, 'max_depth': 13, 'min_samples_leaf': 3}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:12,568] Trial 31 finished with value: 0.8695659295659295 and parameters: {'classifier': 'RandomForest', 'n_estimators': 103, 'max_depth': 14, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:13,099] Trial 32 finished with value: 0.8677477477477478 and parameters: {'classifier': 'RandomForest', 'n_estimators': 92, 'max_depth': 15, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:13,692] Trial 33 finished with value: 0.8677641277641278 and parameters: {'classifier': 'RandomForest', 'n_estimators': 124, 'max_depth': 17, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:14,149] Trial 34 finished with value: 0.8641277641277642 and parameters: {'classifier': 'RandomForest', 'n_estimators': 109, 'max_depth': 13, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:14,454] Trial 35 finished with value: 0.8713841113841113 and parameters: {'classifier': 'RandomForest', 'n_estimators': 64, 'max_depth': 11, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:14,756] Trial 36 finished with value: 0.8550696150696151 and parameters: {'classifier': 'RandomForest', 'n_estimators': 53, 'max_depth': 9, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:15,231] Trial 37 finished with value: 0.8586895986895987 and parameters: {'classifier': 'RandomForest', 'n_estimators': 72, 'max_depth': 8, 'min_samples_leaf': 6}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:16,170] Trial 38 finished with value: 0.8623095823095823 and parameters: {'classifier': 'RandomForest', 'n_estimators': 268, 'max_depth': 11, 'min_samples_leaf': 7}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:17,042] Trial 39 finished with value: 0.8568386568386568 and parameters: {'classifier': 'RandomForest', 'n_estimators': 209, 'max_depth': 12, 'min_samples_leaf': 4}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:17,838] Trial 40 finished with value: 0.8695495495495494 and parameters: {'classifier': 'RandomForest', 'n_estimators': 185, 'max_depth': 7, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:18,223] Trial 41 finished with value: 0.8677477477477478 and parameters: {'classifier': 'RandomForest', 'n_estimators': 85, 'max_depth': 14, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:18,720] Trial 42 finished with value: 0.8695659295659295 and parameters: {'classifier': 'RandomForest', 'n_estimators': 103, 'max_depth': 15, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:19,158] Trial 43 finished with value: 0.8677313677313677 and parameters: {'classifier': 'RandomForest', 'n_estimators': 65, 'max_depth': 17, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:19,615] Trial 44 finished with value: 0.8695659295659295 and parameters: {'classifier': 'RandomForest', 'n_estimators': 114, 'max_depth': 13, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:20,255] Trial 45 finished with value: 0.8677641277641278 and parameters: {'classifier': 'RandomForest', 'n_estimators': 133, 'max_depth': 16, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:20,632] Trial 46 finished with value: 0.8641605241605241 and parameters: {'classifier': 'RandomForest', 'n_estimators': 82, 'max_depth': 12, 'min_samples_leaf': 10}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:21,412] Trial 47 finished with value: 0.8677477477477478 and parameters: {'classifier': 'RandomForest', 'n_estimators': 222, 'max_depth': 14, 'min_samples_leaf': 8}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:21,951] Trial 48 finished with value: 0.8677641277641278 and parameters: {'classifier': 'RandomForest', 'n_estimators': 145, 'max_depth': 10, 'min_samples_leaf': 9}. Best is trial 11 with value: 0.8713841113841113.\n",
      "[I 2025-11-13 18:44:22,922] Trial 49 finished with value: 0.8622768222768222 and parameters: {'classifier': 'RandomForest', 'n_estimators': 239, 'max_depth': 18, 'min_samples_leaf': 1}. Best is trial 11 with value: 0.8713841113841113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Optuna Results ---\n",
      "Number of finished trials: 50\n",
      "Best trial:\n",
      "  Value (accuracy): 0.8714\n",
      "  Params: \n",
      "    classifier: RandomForest\n",
      "    n_estimators: 287\n",
      "    max_depth: 16\n",
      "    min_samples_leaf: 8\n"
     ]
    }
   ],
   "source": [
    "# Run the Optuna study\n",
    "# create_study directs Optuna to maximize the objective function's return value.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50) # Run for 50 trials (compare to 135 for GridSearch)\n",
    "\n",
    "print(\"\\n--- Optuna Results ---\")\n",
    "print(f\"Number of finished trials: {len(study.trials)}\")\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value (accuracy): {trial.value:.4f}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6adda8a",
   "metadata": {},
   "source": [
    "#### **4. Using the Best Model**\n",
    "\n",
    "Once you have the best hyperparameters from Optuna, you create the final model with them and train it on the entire training set. Then you do your final evaluation on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4142133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier': 'RandomForest',\n",
       " 'n_estimators': 287,\n",
       " 'max_depth': 16,\n",
       " 'min_samples_leaf': 8}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4e863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Set Accuracy: 89.86%\n"
     ]
    }
   ],
   "source": [
    "# Get best params and create final pipeline\n",
    "best_params = study.best_params\n",
    "# The 'classifier' param is from our objective function, we don't need it for the model itself\n",
    "best_params.pop('classifier') \n",
    "\n",
    "final_model = RandomForestClassifier(random_state=42, n_jobs=-1, **best_params)\n",
    "final_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', final_model)])\n",
    "\n",
    "# Train on the full training set\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the unseen test set\n",
    "test_accuracy = final_pipeline.score(X_test, y_test)\n",
    "print(f\"\\nFinal Test Set Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5ffef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
